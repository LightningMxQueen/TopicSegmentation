18
start start recording tomorrow repeat consider winter semester want look definition classifier core concept elli course sketch structure pattern recognition system classify pattern summarize theory classifier stage talk bit optimality intuition suppose classifier summary comment literature read detail let start structure pattern recognition system sensor camera microphone scanner preprocessing preprocessing stage discuss detail winter transform signal signal image transform image reduce noise instance enhance edge thing happen preprocessing stage learn lot filter thing process signal compute feature reduce record signal feature vector pattern recognition feature vector fix dimension feed feature vector classifier class number form notation thing change summer semester feature class number denote reason formula work formula use notation field classifier end winter semester classifier classifier network semester relax constraint axe vector summer semester analysis consider feature change instance dimension record image record image feature vector vary vary length question compare vector build feature space similarity measure question idea instance speech recognition speech signal guy speak word speak feature sequence vary length compare feature sequence sequence question winter semester consider distance vector space summer semester learn decision boundary observation type learning strategy supervise learning strategy supervise learning mean sample pattern feature set accord observe pattern class label instance hornegger audience hornegger compute feature associate utterance label class number word hornegger instance klein record example label word klein supervise learning tell pattern class pattern belong learning observe feature vector tell word speak class information case know class question train classifier base observation class label learn method semester learning sequence feature set learning stage imagine lack information class label bayesian classifier rewrite decision rule talk bit notation let consider feature vector feature vector dimension instance object recognition problem use color value area object feature feature use basis class decision denote class number class label beginning course week week consider class decision problem consider class look reason depend topic tell class numbering class number probability pattern class example probability mean example text sueddeutsche zeitung york time probability read observation probability find obama select word probability word obama knowledge probability hornegger new york time kind information use classification probability class capture measurement close eye tell object decide basis probability case probability select probability feature vector case evidence literature probability observe feature feature space tell feature distribute feature space class tell probability observe feature class number probability know heart future thing model join probability probability feature vector class probability class density probability density function feature vector class use knowledge dependency probability observe class change ordering probability probability probability class feature vector look beginning need need ignore need density class density literature class use notation mention class probability let look bayes rule know school yes bavarian abitur know probability rewrite probability probability factorization rule know know write way decomposition look joint density rule appear fact use follow lecture use rewrite posterior sit think write posterior use equation look divide rewrite evidence evidence compute density marginalization hear density sum value end rewrite evidence density refactorize time sum rewrite probability term component probability multiply class probability mechanic leave comfort zone feel find slide web way find typo let know slide semester typo agree prime prime remember rule arithmetic probability consider rewrite posterior term ratio marginal denominator comment evidence marginalize density mention compute probability probability marginalization density marginalize variable replace sum class integral feature vector prior compute type marginalization way notice type variable problem future switch mix thing write integral write sum point feel sit think integral sum know course know course dig detail throw integral mean sum feel let summarize decision rule write class class denote value star way maximum probability look class evaluate class probability end decide class value decision rule rewrite thing accord bayes rule denominator evidence maximization constant bring influence maximum scaling function maximum function position maximum change function value change shape optimization function function change leave look forget evidence marginal slide product probability parameter know product number tend multiply number pattern recognition run problem machine accuracy work pattern recognition people people statistic people machine learning apply function product change value function value position maximum change position maximum apply logarithm change position maximum look look logarithm product know property logarithm replace multiplication summation optimize sum probability class decision need need prior remember obama hornegger probability look measurement need class condition need class probability characterize topic lecture pattern analysis modeling think exam ask pattern analysis teach course lean posterior question point mention beginning set feature feature space vector space fix dimension observe feature vary dimension sequence set feature set feature characterize object image look pattern recognition pattern recognition winter classification feature vector fix dimension option look formula care prior class conditional try model posterior type decomposition strategy discuss literature modeling try posterior modeling estimation prior class condition way consider way consider think follow winter semester feature space class feature vector class feature class example know draw decision rule decision boundary decide class feature vector hand class feature hand think problem assume decision boundary form form point function achieve value write probability base fact decision boundary talk problem winter semester learn tell probability look level level set talk know line line question method compute decision boundary end day generalization property classifier generalize training datum datum generalize mean classify feature vector base decision boundary compute classifier try classify element training set problem probability representation decision boundary write probability probability model draw function decision boundary write probability classifier base decision rule presence cost function cost lose function function class number class number loss feature vector belong class assign class lambda decision feature vector belong class classify class class loss decision pay euro penalty lose euro decision feature vector word obama decide mean hornegger misclassification pay pay cost function loss function pay euro dollar dollar matter loss function scale matter let decision decision pay euro let euro contribution business classifier classifier guy generate loss loss loss generate classifier classifier generate loss value loss define loss function element assign prime weight probability observe feature vector prime typo fix prime observe feature vector probability feature vector belong class prime prime assign class marginalize fix loss feature vector belong class prime assign class note book write slide fix loss function loss function loss function want minimize decide class minimize loss loss define loss correction prime think sum decision weight decision weight feature vector belong class agree factor factor sum sum explain let hook let hook sum class sum class know class decision factor class pay penalty sum point point decision classifier find class assignment minimize term mean mean cost loss vector prefactor posterior value prefactor weight decide class probability weight rest sum value idea sum zero choice zero point factor follow minimize sum remain element mask prefactor maximization probability classifier classifier minimize loss cost function minimize loss prefactor guy contribution sum posterior classifier accord loss function apply decision rule classifier classifier talk classifier mean learn reconsider structure classification system talk learning basic probability know school arithmetic rule optimality classifier apologize typo fix talk method model good detail book professor niemann chairman classic book duda hart publish beginning seventy come edition year book pattern recognition theory detail let look problem model posterior chapter regression explain detail talk regression sound topic want consider relationship posterior function look decision boundary look problem learn regression talk relationship regression network look function sigmoid function know feed network instance relationship network theory question way candidate environment camera dare advantage compare lecture table microphone record talk neighbor guy tell bullshit record hide camera identify people know mean remember agree recording sit row video yes know law problem know know care run law problem recording know use proof lecture leave party line know know know bit comment talk siemens company regression remember sound regression model model probability try model candidate lady bitte address problem idea idea start learn learn life money consider basis base interview siemens people ask know regression think level detail people type interview look class problem tell class class confuse let look know rewrite use formula divide class evidence evidence rewrite probability time class time class algebra apply probability theory agree divide numerator denominator time divide numerator divide denominator component divide ratio posterior class posterior class remember write guy write function squeeze function know note book write train home hour system work frustrated candidate operate function add subtract change look look function professor write log base course figure thing home logarithm function write power log ratio rewrite power log ratio log numerator log denominator want sign minus sign change ordering lock function power function guy write rest day find argument function decision boundary trick look posterior use math know school grow bavaria use marginal start remember guy write form enforce miss function add subtract way step apply function function algorithm happen look look log rewrite guy use sign time sign state log log decision boundary function look happen prior class conditional gaussian decision boundary shape structure answer type probability model draw decision boundary hand type posterior apply neighbor classifier write term classifier classifier class conditional gaussian question question reconsider guy tell decision rule imagine come slide typo imagine typo rewrite use school math end characterization posterior think follow step math posterior write function power function prior class problem posterior class class sum choice label probability probability sum know write probability power yes calculus end representation exponent sign exponent flip class representation class representation difference sign function want write probability class flip sign probability look understand function future function network sigmoid function talk logistic function sigmoid function mean close eye power minus function function property use property function derivative sigmoid function fulfill property mention let compute derivative apply chain rule derivative power minus square use chain rule compute derivative think minus miss check write slide typo plus splitte square factor power divide power minus divide numerator denominator power minus power minus power minus divide power minus product power minus power time know posterior class posterior class know minus compute derivative apply chain rule term power minus calculation minus time minus product posterior write way derivative sigmoid function know derivative sigmoid function feature plot sigmoid function scale factor look kind step curve look step curve probability class decision boundary function separate feature set candidate posterior decision boundary point decision way way intersect place intersect place posterior value select value compute decision boundary classifier rewrite know master rewrite thing turn equation sense decision problem basis probability obama probability hornegger read newspaper classification problem case presence class look ratio look ratio divide ratio decision boundary ratio logarithm ratio know decision boundary decision boundary decision boundary function exponent sigmoid function write probability know posterior class flip sign draw decision boundary representation plug posterior method write posterior regression sound let look assume log divide function know decision boundary statement require rewrite lemma logarithm logarithm want rid logarithm feed function ratio posterior power multiply denominator multiply term power class number know class problem posterior sum rewrite posterior term posterior plug property posterior repeat apply property sum resolve equation abitur bavaria learn class year school time equation rewrite term equal power divide power divide power sigmoid function sigmoid function class decision boundary write probability look follow situation classification problem use problem dimension deal feature dimension feature dimension class let use color increase value lecture evaluation evaluation course know know know happen evaluation know happen know happen evaluation feel read thing pointer comment write guy loss function define way derivation optimality classifier hurt want tell want tell class draw decision boundary let alpha time alpha affine function rewrite term notation assume component feature vector value scalar product vector point talk function mean affine mix think course work detail home detail home representation posterior look class number power alpha alpha transpose plug posterior use regression use function use sigmoid function know class conditional class conditional class conditional exponent function minute class conditional instance gaussian class share covariance matrix decision boundary family probability gaussian know point view model probability probability sense like like let reconsider optimality classifier generative modeling scheme logistic regression look modeling scheme consider characterization posterior rewrite probability term function function decision boundary exponent exponent function result winter semester discuss classifier discuss classifier come question thing relate know thing relate know deal sigmoid function framework network winter semester remember let look example let assume feature vector feature dimension feature class distribution feature class distribution model bell class class class time value feature vector value distribute class value value distribute observe feature feature vector feature vector probability belong candidate value posterior class posterior class decide class start area boundary boundary thing start posterior intersect decision boundary pattern recognition people pattern analysis people care feature decision boundary look know area class situation position boundary feature case draw line job separate training set feature generalization property instance observe feature decision boundary class decision boundary class decision boundary class depend choose type strategy use compute line method compute line decision boundary question feel like simone let look example let look example pattern recognition think class fix dimension feature vector choice use gaussian talk people know people office industry professor pattern recognition problem bring glass use gaussian case work gaussians choice know answer probability theory relate question exam gaussian let let assume class density gaussian gaussian dimension dimension dimension feature vector think guy use notation prefactor time power divide prefactor determinant determinant rid rid power know multiply matrix constant compute determinant prefactor value tell dimension column vector write way need variable explain tell people formula hornegger lecture look rid trick use class density write posterior form term term component term component offset intercept bias intercept bias literature function decision boundary look parabola assume class conditional gaussian constraint know simone help typo look ratio ratio posterior logarithm decision boundary notation know posterior class prior class density function case distribution depend vector sigma covariance matrix definition write notation use literature represent gaussian time class divide time class split property logarithm element sum prior ratio tell prior prior shifting decision boundary factor depend measure vector imply offset decision boundary use knowledge shift bit decision boundary ratio logarithm forget knowledge decision boundary knowledge think winter semester think happen introduce prior know decision boundary use knowledge obama press hornegger decision boundary situation feature class decision problem ratio class conditional plug zero plug prefactor feature vector prefactor power imply root prefactor half offset offset observation gaussian instance share covariance class let class covariance matrix mean vector lead element sum covariance imply shift decision boundary sigma pattern recognition mean use know abitur knowledge manipulate thing bit understanding thing observe prior imply offset decision boundary sit think class prior deal thing prior covariance matrix class ratio ratio offset information compute decision boundary let shift play bit gain information happen leave function function logarithm let look apply logarithm numerator logarithm denominator game log add subtract forget operator bit manipulation instance sign flip change order start class number characterize class number cosmetic exponent exponent rewrite thing bit know mes term term term term sit home check find error sign write email figure chance find typo term term term let look term difference covariance matrix statement difference inverse covariance vector multiply transpose vector direction alpha alpha vector read alpha decision boundary use class conditional gaussian result elli winter semester decision boundary use gaussian degree polynomial decision boundary degree decision boundary line density share covariance matrix difference situation class covariance matrix know decision boundary line write posterior term class multiply prior expression sigma write decision boundary term sigmoid function alpha transpose alpha question come practice class feature label learning find line split training set class use representation sigmoid function compute alpha alpha zero representation gaussian statistic estimate sigma question result result decision boundary state sigmoid function decision boundary assume gaussian assume gaussian knowledge restrict line subset represent line manner compute use method question end day record sample check classifier people literature research bunch classifier train classifier capture set feature look classifier job recognition rate generalization property classifier classifier cook book tell situation use classifier situation use classifier component lead statement bachelor master thesis lab dig topic implementation way solve problem application application orient problem know application problem find framework solve problem end day implement compare state art state art find job measurement simulation datum mean business work man work datum remember definition alpha alpha read thing formula prefactor half look sit computation let look alpha zero alpha zero prior class class share covariance matrix fall case decision boundary term difference length difference length vector class length vector class label sigma entry simone add fault button darstellungsoptionen darstellung let reconsider end day difference vector vector centroid generate let look decision boundary example point point estimate covariance matrix set estimate mean value plug formula matlab curve decision boundary curve decision boundary function look prior mean point probability circle sample consider prior set half shift decision boundary shift decision boundary class class probability pull decision boundary feature space information class pull class share covariance matrix share covariance matrix difference decision boundary decision boundary plug thing sigmoid function know exponent sigmoid function draw line classification problem boundary decision boundary compare decision boundary assume covariance classifier job training sample defer defer output area feature decision boundary assign class decision boundary assign class problem point pull use decision rule use decision boundary know choice information consider component check classifier perform perform rule thumb pattern analysis pattern recognition people datum datum datum job imagine feature area area training set decision boundary look come assign class lot datum lot datum decision boundary find classifier yes think problem training datum parameter estimate instance covariance mean vector prior alpha representation type decision boundary number parameter know parameter datum need come estimate parametrization decision boundary advantage need datum estimate parameter comment note class conditional gaussian share covariance argument function sigmoid function flapsy function question exam know decision boundary relate classifier tell story result family limit gaussian decision boundary feature follow density gaussian distribute family carry decision boundary write probability density function term function term parameter theta phi location parameter dispersion parameter detail lecture lecture statistic family class element family dispersion parameter lead decision boundary proof plug ratio log ratio function look decision boundary end assumption dispersion share density use representation express instance density poisson density density distribution density course statistic fulfill constraint map representation mean express term family class density member family distribution dispersion decision boundary component consider result burn shelf brain decision boundary cover gaussian class gaussian covariance estimate alpha alpha datum underlie constraint gaussian covariance candidate mean feeling follow mean kind know scene mix minus plus course care detail way explain fault reason course joke question learn regression discuss tomorrow thank tomorrow afternoon hall
tuesday session consider beginning topic talk classifier bayesian decision rule maximize probability build classifier respect loss loss function proof proof type fact chapter start look regression apply trick rewrite posterior use decomposition probability know ratio trick divide denominator denominator expression apply function logarithm map thing end representation sigmoid function probability rewrite arithmetic operation function look sigmoid function function power function define decision boundary classification problem class decision boundary representation write probability class know posterior power depend class consider sigmoid function attend pattern recognition winter use network sigmoid function use network use network regression perceptron look derivative sigmoid function property derivative function function property reuse compute derivative estimate parameter function sigmoid function look step function approximate step function choice prefactor step function look decision boundary start look example example consider let assume class probability class represent gaussian formula gaussian write heart strategy exam write gaussian assume class probability gaussian probability function form term component feature vector term constant plug thing decision boundary fix web decision boundary ratio divide ratio logarithm plug thing computation turn function matrix difference inverse class class share sigma class share sigma gaussian class conditional covariance matrix sigma sigma sigma sigma difference function case distribute feature share covariance decision boundary line decision boundary result look picture decision boundary affect prior prior offset look line compare yes point know generalization property decision boundary imply classifier problem area area area classifier behave depend datum choice imagine mean type function separate training datum set hold function question choice question burn brain class conditional gaussian share covariance exponent function function affine result consider function binomial poisson distribution function family density basic statistic probability theory course question learn regression function question set feature denote pair feature associate feature class number let training sample pair feature vector associate class number training assume regression let function parameter theta depend feature vector estimate parameter function alpha time transpose alpha question estimate parameter decision boundary observation idea idea let let let write let think power alpha transpose alpha question alpha alpha compute set training sample compute idea tell tell end type intuition intuition learn bit apply apply likelihood estimation apply likelihood estimation remember likelihood estimation work apply likelihood estimation likelihood estimation follow assumption hear likelihood estimation hear likelihood estimation likelihood estimation assume follow training sample handwriting assume mean pair point training sample training sample maximize observe set training sample write probability probability product pair product probability parameterise alpha alpha unknown select alpha alpha product probability achieve value product probability achieve value idea sample assume compute density training sample multiply know variable type factorization write product probability pair parameterise parameter compute parameter achieve maximum let look formalise slide let rewrite posterior assume sigmoid function theta transpose scalar value scalar product vector sigmoid function write write reason mean thing switch situation choose representation mention training set training sample apply method choice likelihood estimation look rewrite probability case use type notation class class exponent term prefactor probability case exponent term write probability identify thing look bernoulli distribution know course statistic product posteriori class feature vector multiply product know number number ranjeed pardon probability value let majority vote think value think value value example let gaussian probability variable value density function density function hast fulfill property value variable remember course probability theory evaluate density function point probability number value variable sum probability observation value variable consider interval consider interval probability probability fall interval integral function value integral domain people variable constraint value case variable case class number number class remember slide think set slide point variable case sum case integral write probability product probability ranjeed mention value product factor example training product value number know shrink value apply logarithm likelihood estimation use lock likelihood function rid product rewrite thing term sum run scaling property know scaling problem product factor plug probability formalise probability logarithm power power apply rule work logarithm exponent prefactor exponent prefactor look mean look bit study information answer cross entropy cross entropy kerstin study finger way experience note expert log likelihood function entropy detail people information information log likelihood function function mean function minimum find minimum method let point think follow optimization problem function look function function property choose point curve connect curve definition function function definition know mathematic draw epigraph graph epigraph set know set point set connect line line set set rule remember belly belly rex belly rex connect point set set function connect point fall function graph epigraph function set mean time find minimum start optimization pray god find minimum task function detail function expert function property mean shape function mean minimum use kind gradient method find minimum talk bit week optimization week week week detail compute gradient point follow gradient step step end minimum likelihood estimation function function parameter remember sigmoid function power minus argument function parameter look mean solve set equation solve want solve optimization problem need method tell compute gradient let look gradient think gradient compute know yes let ask question know respect variable compute gradient mean compute gradient gradient regard compute gradient regard mister puma regard theta know collaborate adidas tell puma shirt expect comment apologize regard theta compute gradient regard theta let pick component theta theta vector theta vector pick component component want compute gradient let look function compute gradient regard theta gradient constant worry logarithm derivative logarithm use logarithm compute derivative regard theta function function compute derivative component regard theta stage apply chain rule logarithm compute derivative regard component chain rule abitur know year pre factor sum logarithm disappear compute derivative regard regard logarithm end derivative derivative remember derivative derive mention regard component remain component feature vector component feature vector log likelihood function regard parameter theta prefactor time dime factor element feature vector gradient know gradient point know surface function think alp stage compute gradient direction gradient point direct direction descent change point change use norm look week remember gradient point direction descent compute gradient gradient point direction flip sign know direction find minimum function follow gradient change sign function follow gradient compute gradient result rewrite clean thing bit expression gradient mean look mean class number approximate function approximate function difference know deviation use weight feature vector position feature vector component gradient compute difference class number sigmoid function multiply component feature vector component rewrite matrix notation dieter week compute matrix notation look component vector theta difference scalar multiply feature vector gradient mean know compute gradient follow gradient minimum compute let minimum function scheme newton raphson iteration intuition newton raphson work curiosity hear newton raphson life life newton raphson core idea newton raphson core idea newton raphson glueck gehabt ask mean axis mean answer interpolation pardon iteration find iteration scene remember guy explain lecture know idea let think point point newton raphson newton raphson compute order taylor approximation point case parabola step newton raphson function compute minimum form position minimum point function consider approximate taylor series end order degree parabola compute minimum point story minimum run conversion newton raphson converge method work dimension work dimension dimension rule thumb dimension function iteration worry thing engineer consider find formulation pattern recognition problem image processing computer vision problem way deal function function minimization maximization function problem forget newton iteration know week formula work formula follow idea remember function order taylor series look formula taylor series know compute derivative taylor series set iteration point problem need order derivative problem deal problem space compute case procedure compute inverse hessian application consider newton raphson iteration require gradient order derivative case hessian compute hessian function idea work hessian function iteration scheme newton raphson iteration hessian inverse hessian multiply gradient follow illustration need hessian detail hessian mean write base formula look prefactor time transpose matrix follow iteration scheme thing thing newton raphson work way solve optimization problem mean think think function function start compute maximum mean taylor series parabola compute crossing derivative taylor approximation point parabola end write formula formula solve maximization minimization problem concave function formula think function look maximize minimize function use newton raphson scheme end function use formula course introduce pardon thing mention teach slide relationship perceptron regression mean know estimate prefactor argument sigmoid function use know derivative find iteration scheme estimate parameter find decision boundary think network look mean network illustrate graph input note let input note write write perceptron bias intercept bias sigmoid function sigmoid function class class sigmoid function remember sigmoid function power network introduce note weight summation input element weight alpha alpha alpha alpha alpha alpha sum alpha time function component feature vector assume apply thing sigmoid function class decision regression regression network winter semester attend lecture winter semester perceptron regression learn training algorithm reinvent network people thing know use likelihood estimation year use newton raphson iteration compute maximum wait network people training use intuition skill solve problem lesson learn mind posterior posterior way implement classifier posterior write term function posterior write function case class probability probability decision problem decision boundary write probability require decision decision boundary distribute feature vector class function decision boundary mind gaussian share covariance decision boundary line week mind ask exam regression book like buy like pattern recognition pattern analysis element learning book publish time think edition cover lecture write access theory book library apply regression example regression write viewpoint person work statistic computer science pattern recognition computer vision thank attention monday
welcome monday session monday minute minute build picture mind map follow party line story line lecture talk pattern analysis pattern analysis core concept winter semester decision rule classifier classifier property classifier apply decision rule turn respect loss cost function decision rule decide class maximize maximize decide class maximize probability feature vector maximize lecture week decision rule accord loss apply decision rule end loss classifier change cost function thing look decision way pay dollar currency home country rupee pay rupee decision type cost function place world apply decision rule consider model consider feature vector pattern recognition future lecture consider feature set feature sequence vary length squeeze frame work way model probability model modeling scheme write thing way rewrite probability use base base rule type component log class class density class density scheme modeling scheme characterize probability introduce class case consider detail transform function function sigmoid function look result exponent function define decision boundary plot decision boundary find sigmoid function form manipulation density math apply end type formula look class probability function look family probability density function function use pattern recognition gaussian look gaussian tell want build classifier choice start gaussian class probability experiment turn gaussian work understanding decision boundary look use gaussians session feel sit want case gaussian decision boundary look jochen order polynomial characterize function function case covariance matrix share covariance matrix decision boundary result result tell probability use class density gaussian use prior prior decision boundary look tuesday week prior kerstin shift shift decision boundary translation insight find think thing winter semester talk classifier lot think relationship classifier relate decision boundary understanding understanding want want talk approach approach want talk approach use pattern recognition work research business people build classifier hear pattern recognition pattern recognition theory know engineer start classification problem build work build classifier life turn solution work problem approach use people idea patter recognition build system base approach slide base approach word idiot base like fit situation let look idiot base base know version sound find set slide like window base control love window guess cross work das talk talk independency assumption look use idea base framework gaussian class conditional independency assumption try motivate base approach use idea use work fact kind people work pattern recognition theory algorithm perform classifier reason training datum thing work set training sample presence feature idea learn winter semester reduce feature space avoid curse dimensionality thing clue image follow idea need feature color area diameter curvature feature image know curse run problem idea apply base work feature work idiot base understanding base imagine come idea try work thing let look class density class density feature probability density value feature vector class feature vector know feature vector generate set component let feature vector rewrite density term component feature vector rewrite write component component component apply base rule base rule time know rewrite concept condition inherit condition probability use probability component probability component prefactor factorization agree agree yes component factorise thing factorise thing write probability product use base rule agree base people independency assumption factor depend predecessor precede component vector assume component vector rewrite product base assume component feature vector component feature vector assume feature vector assume component idiot assumption violate world situation problem simplify lot assumption complexity model complexity probability density function lot degree freedom simplify life lot run run issue curse dimensionality reconsider curse bit set slide week know winter semester space distance feature vector space feature vector border border space consider independency assumption reduce effect feature space pattern recognition people use independency assumption lot submit paper come reviewer know introduce independency assumption justify find argument idea point point base feature vector component type idiot assumption got base classifier independency assumption probability write way board board let look example affect decision rule decision rule write mind map morning apply follow concept compute probability maximize probability rewrite term product ignore evidence denominator depend remember lecture class probability factorise way base assumption incorporate component feature vector decision rule look apply base idiot base ignore prior know let look example concept affect classifier expect decision boundary function time expect decision boundary work engineering skill intuition expect assume component imply covariance matrix vector number vector size covariance matrix jochen covariance matrix tell tell variance coordinate element tell pardon covariance express kind dependency component happen covariance matrix matrix matrix matrix end gaussian covariance word class share covariance matrix share covariance matrix expect decision boundary function component component feature vector decision boundary decision boundary share covariance covariance matrix understanding let look detail assume man feature vector feature vector assume feature vector distribute class vector class component independency matter covariance matrix jochen dimension feature vector time dimension feature vector covariance matrix compute inverse covariance matrix matrix look formula distribution exponent inverse remember exponent inverse remember gaussian divide exponent sigma divide sigma number unknown feature vector component vector unknown vector situation covariance matrix covariance matrix property write thing element element count result gauss count element element column element element nebendiagonale know word let let start entry parameter corner sum half parameter parameter feature characterize behaviour use gaussian estimate class parameter lot imagine need lot training datum estimate parameter parameter idiot come game let idiot idiot idiot following feel feel idiot following class density gaussian assume component rewrite break product consider component component distribute mean component unknown estimate mean scalar estimate variance scalar value unknown estimate characterize density function write think mean variance bring reduce lot imagine mean limit set training datum estimate unknown need training datum reason lot idiot succeed data set training adjust parameter situation covariance matrix lose lose estimate covariance mean vector classifier fail base job look figure know dimension feature vector increase increase formula increase parameter range feature vector base job parameter estimate example idiot life idea pattern recognition attend lecture pattern recognition idea base apply idea work look decision boundary generate order decision boundary assume component feature vector problem assume independency explain dependency generate example decision boundary incorporate independency assumption end use method decision boundary look know happen point misclassifie type question know strategy point decision boundary decide quality classifier mind work summer semester mean care feature separate decision boundary fit concentration feature decision boundary look feature behave decision boundary fit decision boundary classifier job decision decision boundary feature decision boundary mean care classify job find line curve data set need understanding data set come idea separate compare let compare decision boundary area area need future study area classifier fail job case draw conclusion consider logit transform base logit transform use future talk ada boosting concept classify classification come logit transform let reconsider context base context logit transform consider ratio happen ratio decision boundary logarithm level set function decision boundary rewrite probability use prior class conditional evidence numerator denominator cancel rewrite posterior use base rule split factor use property logarithm ratio prior ratio class conditional feed logarithm function class conditional know factorise use independency assumption look logarithm split factor sum element sum depend log log express logit transform term constant alpha function depend simone write face scalar component vector function component component variable model structure model model pattern recognition consider logit base base question technique literature find ton paper people use independency assumption dependency play independency assumption look thing perform example find solution example work component design classifier student thesis lab experiment experiment require work datum experiment thesis look theory literature overview theory algorithm work work exist environment reduce parameter space introduction independency assumption break thing covariance matrix melt covariance matrix parameter tying underestimate concept parameter tying parameter tying parameter tying mean density function share parameter instance parameter tying use assumption class conditional share covariance sigma class class sigma tie parameter class share parameter tie tie instance covariance matrix sigma sigma sigma square square component share covariance rest rest estimate tie component feature vector feature parameter matrix vector tie share mean tie parameter reduce dimension parameter space value leave degree freedom share parameter tying use underestimate parameter tying line slide start ask student exam explain parameter tying guy know hear comment line slide slice slide line asking list line ask reduce dimension feature space use transform classification apply transform feature space break thing dimension context feature computation function find mapping instance maximize spread feature component analysis hear talk tomorrow reduction feature space mission use idea independence pole pole assume dependency component vector depend component covariance matrix classification process training phase pole pole set assume component instance element feature vector depend number guy mean happen know happen want assume depend pair depend depend rewrite rule factorise use time rest rest write add line skip depend rewrite product density class density term probability memory memory element component feature vector predecessor order dependency order dependency component depend component extend order order order dependency relationship degree freedom engineering skill require dependency assumption use instance speech processing live type order dependency sequence feature recorder speech signal compute associate feature sequence assume feature forget work buy blackberry speech recognition software use idiot base work work order dependency rewrite density use rule density got idea covariance look order model diagonal element predecessor rest parameter idiot case base case assume dependency know scale thing try find parametrization classifier mistake hast record die purpose want think thing fault exam mean clue notice slide happen happen know thing exam web replace fix lecture mean idiot base hornegger base hornegger base base lesson learn base mind work base require set training sample dimension parameter space remember example feature unknown assume dependency bring parameter estimate trade engineering trade work dependency independency dimension feature space force come game force dependency independency example look force come curse dimensionality mean increase dimension parameter space unknown run problem space rule thumb build classifier choice start gaussian base approach look happen bound classifier mean idiot neighbor classifier idiot neighbor classification experience use base try hornegger bayes bayes try forget try reading book like lot year year edition market follow book book write ripley pattern recognition network read book find comment base book write christopher bishop pattern recognition machine learning book year thing recommend buy buy book read write learn lot learn lot record buy market tell mean yes year decide version click know rule lecture talk thing contribute contribute research year try describe concept concept apply research project result generate control look tam tam guess want let mistake annoy mean lose job mistake lose happen chapter chapter like talk bayesian classifier talk regression talk idiot approach come solution mind classifier classifier design focus decision boundary feature decision boundary mind want work know space space want bring thing rule thumb mind work feature vector choice space transformation lift feature space turn space decision boundary happen space look story talk talk classifier tell build classifier pattern recognition class conditional choice choice talk bit feature transform transform feature classification talk know scientist tend introduce abbreviation sound discriminant decision boundary analyze thing discriminant analysis form talk talk rank reduce introduce concept winter semester fisher transform fisher transform concept talk dimensionality reduction concept introduce think tomorrow adidas shoe implement shoe sport shoe hear project adidas hear puma shirt build adidas shoe cushioning device shoe processor processor decision boundary use publication china brasil canada adidas store buy shoe buy software lab explain implement record nike people look story talk predecessor professor niemann chairman come use shoe year know dress reading device room fill computer approach shoe year computer fill room heel running shoe application fall chapter reconsider component analysis winter semester guy know learn use shape modeling result publish year journal use component analysis model shape kidney yes niere kidney build model kidney use model find kidney image talk bit regression end round slide lesson learn reading slide tonight grow point picture mind imagination end understanding intuition concept apply concept problem forget bring shoe tomorrow task kannst morgen sachen bjoern device processor analysis method contrast regression modeling method mean compute prior compute class conditional compute probability chapter regression focus class forget evidence classifier come professor world university know sigma matrix imagine joke come mistake assume class conditional gaussian denote gaussian feature vector parameter characterize gaussian mean vector matrix rewrite term gauss mean require student write formula fail notation feature vector number example vector vector matrix covariance matrix fact classifier hammer decision boundary component class share covariance happen decision boundary covariance matrix matrix end idiot approach end base talk thing repeat underline importance concept fact covariance thing let assume class case class share covariance matrix write decision rule write offset come prior exponent function class prior exponent function exponent function drive decision maximize half minimize half exponent compute difference deviation feature vector vector weight inverse covariance matrix term term importance pattern recognition application mahalanobis distance talk mahalanobis distance mean compute difference vector weight inverse covariance matrix happen identity matrix class share covariance covariance identity matrix inverse identity matrix forget distance vector mean vector mahalanobis distance know extend distance covariance matrix level set know course difference vector point fact length distance weighting distance vector use information covariance matrix covariance matrix identity matrix neighbor classifier prototype case mean vector compute length distance feature vector vector class class class class decide class distance vector class distance consider feature vector exist vector gaussian classifier case classifier assume gaussian class conditional class share sam covariance matrix share covariance covariance identity matrix end neighbor decision rule idiot apply neighbor classifying neighbor classification neighbor decision rule apply gaussian covariance identity identity matrix work work bayesian classifier gaussian classifier base end neighbor classifier degree specialization term covariance ask student think impact prior neighbor classifier build neighbor classifier incorporate information prior prior happen prior offset component translation translation neighbor classifier adjust situation class share prior add constant drive posterior probability example sit exercise sit formula write neighbor decision rule incorporate prior christian ask exam kid kid mean guy remember covariance matrix think remember ask think concept settle know world war economy recover people time think pattern recognition think result day pattern recognition result look literature happen year instance people work compromise decision boundary know share covariance turn covariance know control bit gerome friedman professor statistic come idea regularize type covariance covariance matrix consist element sigma sigma share class steer weight sigma prefactor alpha know want classifier decision boundary decision boundary select alpha weight influence covariance hand decision boundary weight alpha sigma sum alpha weight covariance influence covariance tie density function class play alpha sit matlab environment dieter simone provide matlab environment classification play implement animation know increase alpha look decision boundary thing behave try think decision boundary know choice type criterion criterion use look idea year market time time graduate student come idea time sir depend course classification problem type know happen element decision boundary element assign class class decision boundary assign class thing test set know decision boundary job point point depend test set idea classification week feature feature course draw decision boundary draw know think professor job professor job job job decision rule joke guy rumor professor job rumor professor professor know covariance matrix choice function lecture end set slide function optimize decision boundary strategy strategy survive year method consider support vector machine sound start stage introduce abbreviation machine learning people introduce concept people optimization idea distance half point draw line band margin band know stretch squeeze press point set look band margin decision boundary support vector machine theory base read book book result paper paper idea tend optimization problem find picture tell pattern recognition concept intuition decision boundary decision boundary depend example turn classification problem approach job job week club player classifier method pur classifier combine know soccer team know people goal people set people job politic quote record know decision boundary steer alpha implement animation look decision boundary behave end day decide decision boundary acquire test datum test thing mention thing student field pattern recognition build system training datum test datum mean mean set training datum build margin element training set check percent recognition choice follow feature generate image build classifier train adjust training set capture image look system behave happen student mistake memory leak programming teach lecture programming day teach lecture programming tell look allocate memory delete memory leak student percent diploma thesis minute find memory leak deal concept understand rule work training set test set india training datum testing classifier result percent learn lot gaussians decision rule lot bunch topic consider advantage feature class share covariance decision boundary question find feature transform map feature feature instance mapping end feature phi share covariance matrix want datum normalisation jochen work lab capture image image generate feature class class end day observe know covariance matrix estimate covariance matrix know class covariance matrix look class covariance matrix look sigma sigma sigma sigma jochen guy situation live principle estimate estimate build classifier base assumption ranjeed deal think feature problem estimate know element element parameter gaussian think run problem term dimensionality think need image training suppose christian ranjeed christian hear lecture algebra math attend lecture probability theory probability theory talk know transformation variable transform variable distribute variable distribution deal guy sit liter beer follow find transformation phi map feature result covariance matrix identity matrix apply neighbor classification rule agree story agree let try let try find transformation end feature share covariance matrix sphere datum identity matrix covariance matrix find transformation turn motivate story bit transform datum behave situation illustrate remember write web answer fit talk mapping use s.v.d. find transformation work compute s.v.d. covariance matrix know know covariance matrix course impact s.v.d. matrix time matrix time transpose use sigma confuse write sigma transpose context gaussian use sigma notation matrix s.v.d. use sigma value work german way product look let write slide pardon pardon sigma sigma sigma instance order decrease order value order sigma sigma sigma sigma decompose product matrix square course know notation mean element route route multiply sigma sigma matrix rewrite term power half time power half transpose determinant matrix determinant product value product value product element write product product value sigma bring student value notation product sigma sigma value happen value determinant sense think ask question sense sense sense sigma rank deficiency rank deficiency mean column vector imply matrix determinant sense happen inverse buck inverse inversion element deal matrix inverse transpose compute covariance matrix decomposition value value decomposition factorise factorise squeeze identity matrix shooter happen value decomposition factorization come factor middle identity matrix incorporate decomposition covariance matrix definition density power half covariance matrix end distribution gaussian covariance identity matrix trick distribution derive plug plug determinant sigma rewrite use definition determinant value power half time product value root look exponent replace sigma power inverse covariance product derive value decomposition touch wall bring bring change bring transform transform matrix mapping hand middle identity matrix feature transform mean transform identity matrix covariance matrix class drawback class know class talk talk apply class transform value decomposition covariance matrix class conditional distribute vector transform mean vector power half time vector covariance matrix identity matrix datum belong class know sausage covariance matrix find mapping mapping use s.v.d. sphere datum identity covariance matrix apply transformation feature consider set feature set distribute feature find transform sir think happen happen distribute feature vector happen core message loose loose board answer question sir transform space got point mean class use classification look transform gaussian point run problem class transform point tell word use idea classification tomorrow sense mean feature transform transform compute distance sense use kind know class information incorporate transformation find discriminant analysis apply class identity matrix covariance matrix decision boundary disadvantage feature transform depend class number destroy concept lecture question come slide use depend class number training set compute transform class matlab use matlab classification rule apply require application transform class apply transform think blackberry know apply word recognise transform work windows base system work end lecture thank tomorrow continue set slide
welcome tuesday session pattern analysis tuesday minute mind map picture dig theory consider consider problem liner discriminant analysis talk idiot approach gaussian classifier road discriminant analysis consider distribute feature class conditional gaussian introduce feature transform gaussian level set covariance matrix kind squeeze sausage type structure find transformation result datum covariance matrix level set circle ellipsis find circumstance classifier relate neighbor classifier tell core idea case case neighbor classifier bayesian classifier situation steve steve steve hear tell attend exercise basis pardon need justify mean question steve candidate neighbor classifier bayesian classifier prototype vector compare feature vector compute distance vector need gaussian identity covariance affect neighbor decision rule contradiction mean offset add subtract distance compute prior offset prior come think happen direction shift thing mention apply feature transform notice apply transform class mean feature come start transformation class apply idea compute datum achieve normalization discriminant analysis compute covariance matrix class compute covariance matrix mean stay formula input approach discriminant analysis set training datum way training mean adjust parameter degree freedom classifier training datum learning training parameter estimation base observation word use kind colleague world insist training learning circumstance training learning matter end day training datum degree freedom adjust degree freedom training datum build classifier work end day matter build money idea training datum learning datum observation estimation look pair set pair pair consist component feature vector associate class pair mean feature belong class set training datum datum feature vector label tell class feature belong training datum compute covariance mean care class care class compute covariance set training datum mean vector class label compute vector compute covariance matrix estimate covariance matrix deviation vector sample covariance matrix start start parameter tying class share picture mind mean consider situation feature belong class feature belong class course compute estimate covariance matrix compute formula mean vector coincide register datum mean mean vector bring instance compute covariance matrix plus estimate covariance matrix formula estimate covariance matrix know blue write covariance matrix apply likelihood estimator find formula estimate covariance matrix gaussian likelihood estimation set observation close form estimator compute covariance matrix literature find version people write statistic situation estimation mean discuss lecture notice estimation use denominator case value compute covariance point resolve issue class sigma transform parameter tying class share covariance matrix s.v.d. trick decompose estimate norm form s.v.d. sigma estimation estimate matrix mean value decomposition end matrix time transpose know generate idea phi derive phi mean read book write duda hart describe attend lecture phi phi introduce phi know tell decomposition use prefactor gaussian apply transform end covariance matrix identity idea decompose sigma product derive transform covariance matrix transform feature identity matrix compute mean vector mean vector transform mean vector transformation end know transform mean vector transform prototype neighbor classifier assumption class share covariance matrix standardization covariance course idealise assumption covariance matrix imply error let work end day discriminant analysis dimension reduction dimension reduction mean dimension reduction mean feature vector mean vector vector bring thing dimension transform thing distribution behave datum tell curiosity student exam think undergraduate programming pattern recognition guy ask talk class decision problem know class let feature vector feature vector draw feature vector guy look look team assistant look draw feature vector following follow draw feature vector mean want feature vector mean point decision boundary deal answer deal answer covariance estimation s.v.d. decomposition feature transform class share end neighbor classifier compute distance feature vector transform mean vector decide class feature vector feature transformation decision boundary degree right transform thing know decision boundary transform feature hyperplane consider week detail classification problem transform feature decision boundary hyperplane sense reduce feature space feature space separability function separate class terminology use decision rule look summarize mention time decide class maximize probability probability tell tell classifier rely maximization probability classifier classifier respect cause function use rule decompose probability log class conditional assume gaussian framework logarithm gaussian class share covariance matrix identity matrix bring exponent function function element sum maximize look scalar product vector transform feature vector transform mean vector maintain dimension case compute length difference vector compute length difference vector compute norm power rid root difference vector decide class maximize length difference vector mean minimize length neighbor computation compute distance transform feature vector transform mean vector offset prior class class distribute share share probability offset forget optimization course argument check situation value neighbor classifier incorporate play bit concept know draw figure thing formula student probability hate probability theory feel replace feel look reality guy reintroduce winter neighbor classifier neighbor classifier pattern recognition experience talk student learn lecture discussion department know organise study people lecture understand lecture experience forget restart semester semester experience probability apply value decomposition covariance matrix find transformation theta relationship neighbor classifier expect winter semester know head chair pattern recognition know expect network know mean lecture patter recognition neighbor classifier implement engineer clue pattern recognition mean bring concept know guy destroy concept level understand understand read book understand discriminant analysis find transformation problem decision boundary identity covariance matrix idealisation require transform feature space guarantee set learn winter semester chapter know chapter reduce dimension feature vector learn branch bound method repeat mean know reset restart dimension idea dimension find transformation discuss pattern recognition know instance selection subset feature component function optimize select feature component use decision talk method reduce dimension feature space instance look transform map feature vector feature vector dimension prime prime dimension find know function tell transformation transformation solve optimization problem end instance component analysis objective let idea discuss let look direction reduce dimension increase dimension case reduce dimension pump thing figure prepare bit extend think follow class problem ranjeed number phi know number number want space space know space know space dimension imagine thing change time temperature space space class decision problem let look class decision problem term compute training datum set covariance matrix covariance matrix compute transform phi vector phi phi vector space feature phi apply apply transformation measurement vector feature vector space transformation thing thing classification compute distance vector enforce color wall touch know start come distance distance decide class follow mean think feature space vector decision rely distance point line difference vector vector compute distance observe space spend vector vector feature change relationship distance feature line point vector space spend vector thing space change difference distance vector mean mean instance compute centre vector feature come compute vector base angle alpha decision class decision alpha degree belong class phi alpha degree belong class distance phi distance phi mean guy want thing want face challenge blackboard draw draw figure space break problem class subspace spend vector difference computation project space break computation space compute projection point difference vector look compute scalar product phi transpose time difference vector length vector multiply difference vector algebra sir know mean build learning system adapt mean train use mean think car misclassifie result use retrain system sense train training datum use classifier classify start readjust parameter instance signature recognition know know expect class belong class reject classify check time signature change readapt classifier situation blackberry recognize word know misclassification use classify readapt system screw think class problem class problem reduce classification computation subspace change distance point vector vector span plane plane point project plane compute distance projection distance maintain neighbor classifier result project feature class problem work guy feature vector find way bring dimension work dimension dimension work class problem work class problem break thing feature vector project plane spend vector like job class angle phi difference vector use decision making angle point pointer degree decision rule decide class product half class half ask happen half decision boundary way way coordinate subspace spend difference vector affect distance look geometry class case lift fact class centroid class centroid class centroid class class class represent vector vector span space subspace yes difference affect know space subspace affect know distance subspace spend centroid result lead rank reduce discriminant analysis feature vector class end feature vector know minimum ranjeed memory feature vector device phone question bring dimension dimension firas firas look attend pattern recognition hear component analysis idea stuff feature vector ranjeed look look mapping subspace following result feature spread spread project feature subspace distance vector distance project direction spread maximize distance vector rank reduce bring thing illustration follow argument bring level dimension apply s.v.d. covariance matrix apply phi transform project thing space spend vector apply work set thing semester semester explain follow minute choose subspace yes dimension ranjeed constant idea maximize spread projection centroid follow way follow let use ranjeed visualization problem point vector instance space projection point maximize spread draw manifold video youtube come student petra shake hair bit projection line point project spread line compute mapping job component analysis job know winter compute way write book way way think compute component covariance matrix vector compute covariance matrix point compute component spread define look mapping space ranjeed space phi time transform feature vector phi transform mean vector bar mean vector point spread minimize distance vector point minimize scalar product want find mapping space deviation vector minimize ranjeed choose phi minimize maximize thing maximize spread choose phi power ranjeed constraint constrain variable bit require frobenius norm transform square component component square sum rise use remember day year university lagrange multiplier way introduce lagrange multiplication method spend time prepare slide explain duality gap hear hear basis slide solve optimization problem solve maximize distance spread deviation vector degree freedom mapping ranjeed space constraint optimize mean computation engineer thing solve optimize function function function compute maximum compute maximum compute derivative regard component transform phi condition function compute gradient regard component phi guy book look find think formula sound web page help matrix cookbook dot com mean choose matrix problem matrix cookbook find yes matrix cookbook dot com download idea miss send email extend idea imagine life web page exist time know play thing find solution need formula formula need expectation transpose trace matrix transpose transpose vector find formula compute derivative term matrix derivative form transpose trace derive accord component transpose equip formula compute derivative respect phi multiply thing apply rule function minute hope like know kid page stop minute think minute function compute derivative regard component writing write matrix mean derive regard phi phi think dieter introduce beginning semester bring phi bring phi look trace covariance matrix define vector mean vector remain lagrange multiplier sit think winter semester reformulation write thing covariance matrix class class class rewrite term trace rewrite term trace compute derivative form prefactor transpose factor end transpose matrix time phi time covariance matrix thing derive thing derive write phi sigma lambda phi eigenvalue problem compute transformation phi compute eigenvalue covariance matrix winter semester build thing include projection compute compute matrix covariance matrix transform feature compute eigenvector covariance matrix belong eigenvalue build phi use eigenvector trans stage approach restart week computation board follow normalization bring subspace want bring apply idea implement shoe look monday thank monday
morning monday minute pattern analysis continue topic reconsider picture want lose know forest topic cover learn beginning classifier topic hook chapter discuss pattern analysis decision theory probability play role role consider probability probability observe class feature vector decision rule mean compute probability engineering issue model probability term formula instance compute probability observation mean train learn estimate degree freedom model use observation lecture think evaluate probability talk way probability need model use decision making talk speech recognition system mean imagine use blackberry hour come decision complexity evaluate probability talk efficiency evaluation probability mind map mind pattern analysis teach modeling dealing probability beginning reconsider fact know winter semester lecture come pattern recognition community semester presence loss function cost function probability decision process base probability cost function talk optimality optimality bayesian classifier classifier handwriting student complain fill evaluation form live fact look model probability way model model model model model probability use sigmoid function function play role network discuss winter semester bit learn thing summer sigmoid function carry argument function class decision problem steve carry type information think sigmoid function remember decision boundary level set function decision boundary write power probability class plus minus remember shape sigmoid function know kind step function approximation step function fight problem term curse dimensionality know model ton degree freedom need lot training datum adjust model learn method statistic decision theory pattern recognition analysis introduction independency assumption introduce base core idea base steve dimension decrease parameter space define density parameter space training datum course need estimate parameter observation base vector multiply component assume component feature vector assumption require justification school engineering school argument convince engineer independency assumption mean work work mean care mathematician tell violate assumption guy work theory sell system ton money work mean care violate assumption work sell work week start talk analysis context start classifier idea gaussian classifier steve classifier classifier know decision classification problem office time ask type classifier use gaussian elevator type information classifier class density class density maximize probability know optimize prior multiply class density class density model gaussian gaussian model density distribution talk classifier classifier neighbor classifier relate ranjeed rid decision boundary prior offset component covariance matrix covariance matrix identity matrix end sense prototype vector vector class observation vector prototype vector prototype vector neighbor classifier know hear explain mean prototype vector neighbor classification vector memory vector associate class memory vector come know vector compare prototype vector decide class neighbor belong prototype vector idea neighbor classification prototype vector decision process talk datum normalization problem parking problem parking explanation talk datum normalization sphere datum idea steve projection step way mean pen feature covariance matrix level set function level set contour know squeeze contour want find transform identity matrix covariance matrix idea gain transformation mapping mapping feature transform transform feature feature type probability density function transform compute use s.v.d. yes use factorization covariance matrix suppose s.v.d. factorise factor apply factor feature vector vector end feature know distribute covariance step class project thing feature subspace distance maintain subspace explain tuesday type dimension reduction normalization dimension reduction projection subspace number class reduction dimension drive number class consider want reduce dimension feature apply apply projection space number class transformation transformation mean matrix map feature feature point projection choose way vector class spread mean spread distance mean vector maximize yes ranjeed decide projection know blow thing infinity introduce constraint norm matrix bound norm matrix instance dimension reduction reduction finish time dig discussion follow message course question mean point class let point neighbor classifier point neighbor classifier vector come mean vector come compute distance turn assign class assign class neighbor classifier classifier mean mean compute distance prototype vector prototype vector reduce vector point mean find point classify neighbor classifier prototype misclassifie vector remember winter semester neighbor error probability neighbor classifier relate error probability classifier remember inequality like exam error classifier error neighbor classifier number number prototype result course error probability classifier mean bayesian choose probability posterior business classifier error probability bound remember bound elli use neighbor classifier know error probability classifier neighbor classifier vector course vector relationship neighbor classifier vector run problem number prototype vector classifier intuition kind classifier question want encourage ask question know want encourage ask question kind interaction student lecture know detail write thing exam know figure class case subspace look promise explain detail idea motivate argument feature want bring feature space want point projection maintain information let example mean think follow think object look object shape object know shape object let assume point feature characterize object question object object look object chance classification want object want project image plane shape object use camera camera cam camera know look direction object classification question select projection projection direction projection direction chip plane image plane classify object idea apply point image plane spread image instance look shape object direction way way choose viewing direction way structure spread distinguish object object question select projection direction viewing direction point distance distance feature feature space want find projection space space space distance point application compute vector remember notation vector remember notation agree notation follow formula phi phi transformation space mapping object image plane opt example prime prime bar mean vector vector class class vector compute mean mean mean mean apply phi transform mean weight weight case weight vector class class class feel class case set half sum instance renumbering class start matter term tell term tell term geometry learn detail tomorrow algebra know read mean transform mean mean transform mean mean class mean transformation phi instance phi phi prime transpose time phi phi prime steve term geometry imagine phi sound mean phi phi prime difference vector length vector length vector root vector transpose time measure length length vector sum length vector measure distance mean vector mean mean distance distance distance mean want maximize spread want distance number cancel transform maximum sum length distance square case root length square distance mention mention length vector norm power measure distance square hurt disadvantage square root imply bias value square value impact sum hurt talk strategy deal day measure measure spread got steve got idea measure distance square distance term lambda frobenius norm phi square tell entry matrix phi yes power sum entry message look phi frobenius norm maximize spread maximize spread patter recognition pattern analysis solve optimization problem tell phi transform maximize term compute mean function function function end condition case ask derivative compute derivative regard degree freedom compute derivative regard component phi point web page value solve problem derive function matrix phi respect matrix phi find require rule compute component pain work pain look thing web page need formula need expectation product type rewrite use trace covariance matrix vector need matrix derivative trace form transpose proof thing component computation bring matrix notation let look function compute derivative regard component phi phi phi reorganise term pull phi transform mapping difference transform vector apply phi apply transpose middle vector apply rule matrix vector transpose matrix vector sum divide number expectation compute expectation compute formula rewrite expectation use formula use formula trace phi covariance matrix phi transpose mean time mean vector phi time mean vector transpose phi vector vector case mean mean vector bar vector vector compute mean difference remember figure remember figure mean mean vector compute difference mean vector difference vector normalization forget term look rewrite trace matrix situation trace phi phi transpose middle covariance matrix axis covariance matrix vector covariance matrix vector transform derivative function want compute derivative use expectation rule form compute derivative regard phi leave derivative remanipulation argument matter apply rule trace transpose derive component transpose rewrite use transpose transpose yes transpose factor phi time interclass covariance vector derive regard component phi time lambda phi reorganise bring minus cancel rename lambda lambda bar lambda prime equation matrix time matrix multiple matrix eigenvector eigenvalue problem reduce computation phi eigenvalue eigenvector problem prime eigenvector eigenvalue phi denote eigenvector summarise way derive formula winter approach work component know matrix apply apply matrix calculus result transformation question mean question compensate problem eigenvector eigenvalue question scale component phi mean column vector phi unit length vector scale think think idea scale phi bring column vector like think point point point tell tomorrow think work training datum feature vector label compute covariance matrix class use training datum compute eigenvector covariance matrix belong eigenvalue accord formula check matrix notation break thing vector notation eigenvector form rose mapping phi know winter semester select choose approach return matrix phi bring dimension bring dimension use tool stage projection space establish transform pattern recognition theory fisher transform idea normalization step idea find vector space maximize ratio component covariance matrix class class distance class distance accord postulate pattern recognition know look feature belong class feature distance belong class want maximize class distance want minimize class distance express ratio maximize minimize maximize thing reach goal look projection vector maximize class distance minimize class distance end algorithm normalization projection dimension projection space turn computation use eigenvalue eigenvector product matrix inverse covariance winter semester formalise way want maximize class distance want minimize class distance use lagrange multiplier method multiplier method winter describe replace ratio optimization problem want maximize class distance want distance way rewrite optimization procedure rewrite optimization procedure set following lecture bit talk function look dual solve problem optimization problem case future rewrite optimization problem set pattern recognition winter view concept elli discuss comment dimensionality reduction work thing require set feature wake need feature mean look function apply feature observe search projection maximize distance feature care class mean project thing care class assignment need feature case need classify feature class normalisation remember depend class transform feature transform feature distribute accord limit theorem limit theorem tell remember probability theory apply mapping feature feature compute projection compute combination component vector limit theorem tell sum variable end day circumstance end distribution sum component distribution end distribution know probability theory explanation reference explain theory limit theorem result mind combination variable sum component feature vector weight sense turn produce feature distribute advantage mean feature vector break feature vector know transformation imply distribute feature going implement classifier know select class density gaussian job explain situation situation classifier work mind yes try type result generate feature feature vector compute plot know reach bell apply exercise problem way construction construction feature vector distribute remember limit theorem effect transformation use eigenvector lead feature vector component look magic know compute projection space end distribute feature end distribute feature vector component apply base situation point base work apply thing way distribute feature way construct thing mean disadvantage problem adidas problem know elli talk know class compute space project line spread lead problem class interleave separate projection prefer projection direction maintain class structure point need class information find projection type situation problem adidas problem adidas problem stripe puma problem transition sub chapter point projection method cover lecture work problem projection method think situation exist method dimensionality recon reduction instance sammon transform use lab speech recognition feature space want visualize apply sammon transform component analysis projection method discuss sir think question guess know impact projection space class think end distribute feature end distribute feature let speech recognition lexicon word break thing feature end thing know mean limit theorem theorem depend fact need transform maintain transform map feature vector result independency assumption fact compute eigenvalue eigenvector matrix inverse covariance covariance class distance point think limit theorem colleague watch video guy position know live application work image processing image processing method discuss prohibit work way describe computation problem involve application trick literature thing fly apply idea discuss use method describe theorem lemma johnson lindenstrauss lemma bring item review paper technology discuss result year year johnson lindenstrauss following vector project select subspace view select view shape object feature distance vector preserve space choose projection use feature processing work idea work implementation projection thing work work pointer people succeed pattern recognition idea patter recognition talk application mean think guy lot math algebra geometry probability theory educate way learn way thinking direction method discuss example year year result adidas develop industry partner lab student write software product store brasil buy shoe software run fall require siemens software hook life talk adidas shoe publish result year talk application shape modeling publication january year student write studienarbeit application use use technology year mean method know year let talk adidas shoe bit mean motivate bit idea build running shoe device allow resolve problem run forest surface need shoe case run know road build shoe following measure hardness surface adjust cushioning way system surface surface idea idea class class surface surface shoe implement device processor measure deformation deformation measure decide thing differ shoe immigration december shoe guy type technology shoe spend hour convince shoe carry bomb idea shoe adjust stiffness surface pattern recognition problem measure deformation want classify base deformation measure classification problem think support industry lot version support classifier involve generation technology work tell number choice buy cost version end generation buy generation spend euro version euro wording mean student write slide revolution sport talk revolution sport talk cushioning revolution way watch game peking year motivate student athlete contract partner adidas medal shoe carry shoe software time sport information process running shoe fly datum measure classification adjust system product version allow record datum manipulate shoe lab record datum instance mobile mobile instance run measure heartbeat heart rate measure step measure stiffness surface generate file upload google map run color height encode version visualize parameter run instance point start fatigue thing information skiing year lab carry mobile record track know lot convince mean sound joke road buy shirt sensor measure heartbeat need belt buy shirt future sensor sensor shirt clothe use sensor datum evaluate sensor datum think sensor datum sensor datum evaluation pattern recognition experience business reason collaborate lot sport industry day running shoe picture demonstrate work steer stiffness shoe tube medal medal medal block deformation way tube deform control position medal cable medal deformation heel thing pass shoe bit mechanic boot shoe know start run reboot system course measure surface measure running speed measure fatigueness degree way people run know marathon audience mean kilometer number know run run know measure signal test run lab student know chinese run know use heel signal outlier use heel measure deformation shoe run forefoot running surface speed fatigueness surface shoe need communication shoe mean research innovation think border line mean think year processor car truth processor end car know garage want fix need engineer fix computer stuff year runner run processor fact people carry mobile know run mobile ipod power use thing support athlete cushioning element cushioning element use system change field pointer degree deformation deformation measure change field pattern recognition people signal processing people sampling rate sampling rate measurement measure kilo hertz resolution tenth millimeter deformation know shelf customer product controller allow tell use clock rate hertz buy computer hertz system engineer information communication guy guy kilo byte program memory face constraint use system architecture impact sign algorithm map architecture space look research know method mind hardware constraint state art algorithm engineering platform trade motor cushioning adaptation battery disadvantage shoe battery charge use energy deformation instance battery replace hour running time hour hour marketing guy hour hour hour compare lifetime shoe problem learn hour hour charge euro battery joke constraint perform computer shoe know potential use pattern recognition technology use feature feature compute time perform computer classification system mean imagine run wood know forest classifier work run road classifier notice guy forest surface change state time minute delay know kind run time constraint device mean adjust let step system adapt pair know come run sit drink point shoe start adjust know mean run notice sit point shoe implement classifier decision boundary classifier decision boundary class classify accord decision rule write feature vector evaluate function decide class sign sign class sign class class yes training phase adjust system estimate parameter alpha alpha alpha alpha shoe build use datum acquire lab research lab portland adidas runner compute alpha set runner imagine know adjust alpha runner buy shoe classifier require know system allow training hand customer accept thing training speech recognition system car people accept hear ask assistant training system work mean delegate delegate experiment feature course record signal signal time step deformation hit floor system come hit floor system come way compute feature question feature use classification feature allow classification experiment feature instance compute mean value step compute value compute deviation minima compute deviation mean compute slope use feature feature select end implement shoe shoe shoe shoe compute fly feature use feature classification plot feature green tell surface pink tell surface decision boundary decision boundary implement buy shoe run shoe apply decision boundary feature know finish story december fly immigration trouble fly suitcase end home lose travel shoe want permit lock suitcase know think technology know health problem foot enjoy joke got build system transfer product contact manufacturing unit experience publish paper bjoern eskofier work project right thing talk implement system let talk shape modeling shape model base shape model apply year application instance friend work shape model shape model body walk want express shape body parameter describe surface body shape know belly belly wanna express surface function want parameter steer friend work face image wanna know store million face want find parameter change parameter change face shape job characterize face image use use axis scale axis change thing face shape lab know application sport application focus use shape model segmentation instance patient want find kidney know mean shape kidney people kidney characteristic shape kidney use number support segmentation process mean support automize way find kidney data set way solution propose use component analysis year technology year technology work work want shape modeling think kidney know kidney look kidney kidney look represent shape surface point surface point kidney kidney object point vector instance phi instance represent surface set vector surface point surface point follow shape surface point need know correspondence surface point set surface point define ordering surface point imply ordering vector squeeze feature vector vector vector fill vector component belong surface vector begin squeeze point feature vector like feature vector kidney patient number kidney patient number kidney patient number surface point feature vector characterize kidney use feature vector apply bring feature vector stuff learn bring feature vector feature vector use know projection direction know projection direction variation variation variation build structure use scaling base vector idea shape vector got point surface point squeeze vector break apply projection break bring shape number kidney shape vector generate landmark configuration matrix landmark configuration matrix define way column surface vector patient number vector vector compute column matrix write decomposition associate covariance matrix associate covariance matrix covariance matrix idea talk guy mean covariance point find look formula covariance matrix point compute axis covariance matrix variation variation component analysis compute axis covariance matrix associate vector elli winter accept hand wave argument matrix sigma compute axis pair lambda lambda eigenvalue eigenvector know rewrite matrix know eigenvalue eigenvector rewrite matrix sum product eigenvector weight eigenvalue result know know algebra rewrite covariance matrix base component analysis compute axis decompose matrix sum eigenvalue eigenvector covariance matrix decomposition matrix thing need know eigenvalue eigenvector eigenvalue eigenvector component change change build feature vector sum combination eigenvector vector column vector shape patient kidney end eigenvector weight weight choose weight generate kidney component add kidney follow record kidney compute instance eigenvector transfer telecommunication line factor reproduce kidney structure kidney use number surface description communication face animation instance want characterize face transfer channel mean transfer weight eigenvector reduce data rate apply kidney liver lung apply shape people face application generate train model know kidney generate variation eigenvector parameter change bit kidney kidney person person change parameter representation apply segmentation kidney slice slice instance model use segmentation procedure adjust degree freedom find boundary result kidney kidney kidney kidney application feeling mean shape discussion explain core idea got core idea relationship covariance matrix compute component covariance matrix remember function optimize term covariance matrix point consider decomposition matrix matrix course mean eigenvalue eigenvector end point approximation element sum steer thing eigenvector weight represent object behaviour space training datum example want research project use concept think sense start regression topic end session look tomorrow thank
welcome tuesday afternoon session pattern analysis bring issue discuss monday time think problem come feeling concept talk application example example apply discriminant analysis classifier base concept adidas shoe system marking use system know year system use office read address zip code use base classifier year system fill room heel running shoe concept apply system problem life application application shape modeling think explain notice explain slide state mean point compute axis compute axis axis spread point project axis projection direction space decompose find coordinate system way point map term spread function spread spread spread use vector generate feature vector weight direction weight generate point feature point use combination eigenvalue representation shape use eigenvector combination eigenvector generate eigen shape encode shape term coordinate component use shape representation engineering application use face modeling face face body shape technique encourage search web eigen representation pattern find ton application technology technology apply problem continue look decision boundary way compute decision boundary story end message class find number decision boundary question decision boundary classification problem introduce support vector machine classifier application support vector machine tell choose set decision boundary let talk bit regression regression know difference regression classification ask difference regression classification ask difference classification regression ask regression explain regression steve know pub evening meet girl know ask steve study pattern recognition lady hear deal regression explain regression point answer know fail lady kerstin imagine pub know tell guy steve explain regression think guy let explain find wife regression sample point regression mean fit instance line line hit point minimize distance instance point line regression line regression estimate depend representation line estimate parameter instance use representation know school estimate estimate distance point line regression problem estimate value parameter optimization problem regression mean compute value number interpolation difference regression interpolation kerstin curve hit point interpolation extrapolation extrapolation mean want guess function value set measurement instance function value extrapolate term time problem overfitting overfitte overfitting overfitting mean point know hit point degree polynomial know use degree polynomial following happen hit point error look training sample function jump value predict function value sample overfitte classification classification mean variable estimate difference regression classification case estimate value parameter classification scenario estimate variable class number relaxation technique know class represent number relaxation algorithm force solution class number difference regression value parameter classification variable talk regression classification thing know instance approximate decision boundary regression function decision boundary split feature space class compute regression problem set decision boundary way plug line function feature vector look sign sign tell graph graph know class class look look sign function look sign function way lecture line let decision boundary formula assume alpha norm happen point plug formula prime alpha prime alpha number tell term geometry know distance distance line alpha unit length distance sign distance value value think scenario sign distance way talk support vector machine sign distance distance line feature vector explain sign decision making class number class decision rule base decision boundary probability look type decision boundary plug function sigmoid function probability relationship classifier question compute line use training datum feature vector assign class number feature vector assign class question estimate alpha transpose alpha vector alpha work regression know derivative use newton method solve use regression compute decision boundary winter semester remember remember remember define decision function decision boundary remember remember define decision boundary case know feature observe class number alpha transpose alpha class number minus class number sample vector vector vector matrix vector vector vector alpha alpha alpha alpha dimension feature vector line matrix look scenario equation rewrite matrix notation rewrite line term line vector multiply vector weight weight column matrix column transpose transpose feature vector transpose form line matrix compute alpha decision boundary term regression compute alpha compute think equality hold bit close eye difference difference vector length difference vector choose alpha vector vector solve vector write way transpose transpose definition norm compute derivative set slide close form solution case close form solution alpha alpha alpha matrix know close form close form solution look transpose time transpose power minus gram matrix compute prefactor estimate problem form solution decision boundary use training datum way compute decision boundary regression method discuss instance method compute decision boundary use distribute feature assume covariance decision boundary way decision boundary regression approach use idea regression compute factor define decision boundary use regression setup estimate form solution apologize matrix matter know change term compute minimum know function function solution condition gradient point solution compute gradient regard theta compute gradient regard theta vector alpha theta answer sit component computation probability idea matrix cook book search web mean time change search web check derivative regard theta mean exercise require practice bit matrix cook book life mean waste time stuff mean principle know work look use time use cook book derivative solution form solution estimation week point know story escalation escalate way decision boundary feel instance solution mean hear norm lecture engineering mathematic mean require norm way square norm course know waste time detail impact result wanna tell use norm tell norm sum square value know function norm function function differentiate function point run type problem mean guy start try sand paper approach know use sand paper approach work monday norm algorithm solve optimization problem deal line summary chapter norm norm approximation slide explain detail detail work lecture engineering mathematic ask hell use norm norm accept right feel function use norm tell choice approach thing solve thing set solution form solution use norm norm form solution solve manner form solution norm advantage disadvantage hear disadvantage outlier instance line fitting let want fit line engineering team measurement point bias estimate square emphasize deviation engineer joke engineer engineer engineer engineer engineer stand mustererkennung day professor industry guy teach university girl measure way boy team question hell prefer norm tell way prefer know sand paper approach question norm lead result answer line norm decision rule error rate classifier incorporate knowledge regression incorporate prior regression question think know class want alpha vector alpha vector unit length incorporate decision rule decision estimator mean alpha alpha unit length want line parameterise way unit length incorporate constraint estimator idea year people try regression regularize regression approach read information approximate second compute theta value difference sum line column want entry theta val vector write prefer matrix notation theta equation theta norm minimize want minimize length vector theta include alpha alpha question result mean function minimize compute derivative regard component theta compute crossing estimator look size value lambda value lambda identity matrix impact prefactor component govern identity matrix weight regularizer theta vector lambda value stress argument matrix matrix steer time transpose term regularizer modify estimator matrix invert advantage inverse matrix compute instance game play parameter check thing behave decision boundary work thing idea ridge regression think invent mention literature end eighty end eighty thing introduce statistic pattern recognition community tell look extend function term incorporate knowledge case mean luck form solution case form solution case form solution require optimization form solution crossing gradient estimator end find find care find home mean understanding relationship classifier classifier neighbor classifier relate understanding understanding office like student explain introduce mahalanobis distance item mahalanobi distance chapter mahalanobis distance define way mahalanobi distance mahalanobi distance point transpose sigma power minus distance square inverse covariance matrix exponent gaussian mahalanobis distance neighbor classifier class share covariance matrix share covariance matrix covariance matrix identity distance generalization understand know component analysis winter talk dimension reduction compute decision boundary use ridge regression way compute decision boundary way compute decision boundary base set training sample question comment literature book like want learn algebra issue come deal algebra look book trefethen bau algebra version edition market book summarize lecture hold algebra access understanding algebra way address thing recommend book book mean time book web page tell matrix cook book mean work use work use use favourite book recommend sell book springer verlag book write trevor hastie tibshirani jerome friedman stanford department write book element learning datum mining inference prediction think edition market source concept discuss chapter describe explain book application paper web page chair pattern recognition check publication list december year contribution conference pattern recognition florida way trip adidas shoe suitcase paper explain detail regard implementation classifier adidas shoe feel download paper read find typo let know correct shape model paper write martin spiegel jakob wasza student work diploma studienarbeit paper publish journal computerise image graphic journal appear january year detail want develop feeling topic reconsider diploma thesis studienarbeit master thesis project feeling download paper read try understand feeling compete guy problem feeling come relate issue question let start chapter minute leave slide work talk norm norm regression slide look write complain decision tell norm happen norm question address norm norm exist exist norm research exercise pattern analysis reconsider concept norm talk norm regression happen use norm type optimization problem require solve use norm turn programming programming hear programming study engineering lecture programming course programming mean engineer know mean engineering motivation norm similarity measure chapter summarise issue regression focus look associate optimization problem story end lecture day reconsider product scalar product definition norm talk unit ball norm regression problem thank monday enjoy week
let start monday morning session monday morning start look mind map follow story line know loose context discuss detail mind picture lose story pattern analysis form probability probability know decision base maximization probability classifier know optimality classifier find way model probability method instance talk lot regression method model probability remember formula mind structure probability talk classifier use decomposition decomposition probability time class density function class density function model study detail structure decision boundary find instance prior imply offset decision boundary translation find case gaussian gaussian decision boundary find class share covariance matrix decision boundary function find thing context discuss feature transformation talk component analysis dimension reduction dimension reduction week look regression problem regression find way use use approach find decision boundary decision boundary find form solution problem find form solution problem introduce ridge regression constraint optimization procedure tell vector theta define decision boundary length remember mind lecture run week lot lecture feeling guy tell end day reconsider topic cover notice lot velocity notice drop hope track know mean ask question time decrease velocity feel thing goal lecture bring level pattern recognition pattern analysis reason want end lecture know development pattern recognition patter analysis year stuff know sense teach result seventy way lecture lecture let explanation talk norm think guy talk norm mean know norm know norm problem solve fashion manner form solution think norm look pattern recognition literature pattern analysis literature invention replace norm norm look norm come understanding norm unit ball issue let let look encourage slow feeling work work use switch talk norm look regression problem replace norm norm norm norm find solution concept discuss idea replease replace norm situation norm lead optimization problem sharpen understanding optimization optimization theory core technology pattern recognition pattern analysis spend week week discuss optimization routine perspective look mean learn week gradient decent thing discuss norm relate gradient decent optimization routine apply let talk motivation think look slide week let reconsider norm similarity measure play role machine learning pattern recognition boundary machine learning concept lecture machine learning rename lecture machine learning community share technology reconsider definition fact norm worry list know definition definition definition hour know norm try access know eye need intuition imagination work consider regression problem norm reconsider associate optimization problem look optimization problem algorithm solve apologize modify slide night chance come print web version print hour guy christian guy job mean change minute date kid kid talk product talk norm product spend minute need lecture space product vector feature vector write way transpose time break component write scalar product know algebra talk product line vector multiply column vector product consider product property instance write norm term product want compute length vector mean know define square root sum square component write term product rewrite norm term root argument root product vector root transpose component write write square product write distance product sound observation product matrix student product matrix define product matrix define trace transpose trace trace matrix trace let matrix want compute trace trace kerstin case ranjeed sum element want compute product matrix compute transpose trace term component write way matrix product concept matrix study engineering know expert expert exp correspond norm norm matrix norm matrix use term frobenius norm time frobenius norm define norm vector frobenius norm matrix root product matrix trace transpose sum square component sum square component talk frobenius norm mean component typo miss root christian change student print afternoon version version note frobenius norm mean component square component sum draw root use norm framework optimization problem explain relationship root root function change solve optimization problem solve root function function matter apply logarithm instance probability look position maximum change apply function function want optimize explanation regard root exam formula root remain remain nonsense care case know product vector know product matrix norm express term product norm consider write product matrix definition feel product know matrix need trace product matrix let talk norm norm talk example norm come definition norm function norm denote function bar bar dot dot use vector input matrix tensor function norm number mind norm length vector sense direction vector length length infinity norm length vector norm scale scalar behave scaling factor prefactor typo version year slide pattern analysis write blackboard speed turn week tell story explain detail point know ranjeed space stuff let think term norm vector scale vector mean length bring scaling factor compute length vector multiply scaling factor sense fulfill triangle equality triangle equality norm sum vector sum norm component triangle equation equality fulfil class norm come saturday norm choice norm define sum component power root norm example norm question happen depend evaluate function write norm compress sensing approach vector number non entry norm sir stimmt point norm accord definition thank time norm fix norm accord scaling property require thank literature literature norm think point literature find norm denote number element need check misunderstand want minimize number element behave check point point let look norm norm norm norm set sum value entry norm look function affect component norm shape component vector problem know compute derivative kink norm norm norm know shape function look norm compute derivative function typo square way write way component type function set let know type function know deviation penalty infinity norm norm look limit happen norm turn component talk norm vector look value component bring value vector compute norm norm norm infinity norm result result depend norm value length vector imagine want minimize length vector norm affect result sir limit hold maximum difference difference difference follow slide discuss norm norm talk instance classifier assume matrix define norm structure transpose time form argument root remember mean distribute feature vector compute sigma power transpose decide class value decide class value class index head argmin minimize sigma identity matrix norm introduce matrix norm consider situation form accord matrix mind instance norm norm consider point level set point share distance point lie circle point distance point line distance origin use matrix ellipsis point ellipse distance origin accord norm thing distort distance space affect matrix norm point direction distance point direction let way look level set mean point level set distance origin distance term use norm norm mean sense point distance distance distance distortion norm let reconsider check norm sum component power root sum value know generate play role community infinity maximum component addition consider norm norm relate classifier density know level set norm circle generate got norm norm norm identity matrix identity matrix inverse identity matrix sigma identity matrix inverse identity matrix gaussian distance norm christian mahalanobi distance mahalanobi distance mahalanobi distance term compute difference vector end form inverse covariance exponent function mahalanobis distance vector base covariance matrix base covariance matrix sigma power norm slide got norm measure length vector rid interpretation distance understanding length vector use norm measure distance vector distance function rewrite norm difference vector express distance future decision making classification procedure need compute distance vector decision boundary norm play role use norm classifier end classification result question comment people drop problem lecture let know event o'clock morning accept problem need understand relate content lecture speed complexity product matrix define instance lift idea matrix norm matrix define norm matrix way define norm matrix norm vector introduce let assume norm norm norm vector number integer instance infinity choose vector norm value generate norm matrix norm matrix norm matrix supremum maximum maximum vector apply matrix mapping measure length vector term norm vector norm mean let look unit ball set unit vector vector map matrix vector map matrix vector measure length vector norm instance look vector map matrix vector norm norm matrix element unit ball map look length vector use norm use norm let look case norm mean use norm know matrix mean matrix map unit ball ellipse map vector interpretation matrix mapping use norm norm end follow value value length principle ellipse use matrix mapping property matrix mapping mean study matlab generate matrix use element unit ball look element end contour look matrix map unit circle ellipsis axis ellipsi determine vector column vector matrix value decomposition length vector define value eigenvalue transpose matrix understanding attend image processing winter set slide repeat know mathematic watch video refresher course video start let week read book geometry value decomposition tell norm add square component matrix frobenius norm norm norm express value matrix yes definition talk norm matrix mean value mean length axis length axis ellipse map unit vector matrix got christian play bit let look unit ball let look bit unit ball unit ball unit ball unit ball define use norm norm vector accord norm use unit ball unit ball way infinity idea write infinity mean use norm vector norm square square boundary circle circle norm circle question look norm consider idea norm imply unit ball look idea mean sir rotate degree start discuss case quadrant quadrant quadrant quadrant end unit ball look end unit ball look vector length overlay unit ball difference mean area vector belong norm norm area vector belong unit ball difference look eye mathematician thing mean know structure circle know compute derivative look expect thing thing handle norm case practice know kink structure run problem point unit ball repeat circle vector circle fulfill property require define unit ball unit ball look norm infinity square argument structure fill option fill option know mean rotate unit square rotate unit square unit ball look norm mean transpose root ellipsis instance ellipse ellipse ellipse level time mean video matter circle square rotate square unit ball ask question unit ball constraint optimization instance want solve problem require norm vector constraint boundary unit ball depend choice depend choice norm solution difference let look summary unit ball look understanding let know norm infinity norm look square unit ball look close square round vortex round box draw thing rectangle vortex norm square degenerate circle generate write code segment generate animation infinity norm norm norm norm consider instance point norm end type norm degenerate case understanding square sphere structure rotate type break end case case find figure math book look math book norm thing define figure find figure norm instance want find solution problem estimate solution require norm estimate unit length look level look level hit unit ball solution unit length solution unit length norm point norm distance distance norm estimate think happen solution instance instance end point figure study future talk constraint optimization instance estimate constraint point norm solution infinity norm solution norm solution deal solution need find norm use apply problem follow feeling thing practice feeling know need feeling christian shadow mathematician sim student experience end grade notice student know know decision boundary knowledge knowledge walk boundary exam worry understanding unit ball summarize unit ball vector norm infinity guy write definition slide remember look norm unit ball associate square circle cross let look norm regression regression regression consider matrix equation time time compute instance solve system equation vector range matrix solve solve line column compute inverse matrix determine system equation unknown know range matrix exist vector map know happen matrix line column determine system equation solve aspect come image processing pattern recognition question solve solve look follow optimization problem decide norm difference measure norm residual residual difference vector residual measure length difference vector term norm decide minimize residual idea running shoe mathematician mathematiker know term exist english idea mathematic apply thing hear thing try sense use approach consider optimization problem term norm term norm decide norm norm minimize choice norm result intuition estimation error value estimate value measure denote epsilon future talk residual difference vector vector range residual picture mind range matrix matrix instance range instance vector plane argument vector map vector plane range range define know engineering mathematic vector set vector reach apply element domain matrix vector instance element range compute projection solve system element range case residual range exist fulfill equation picture engineering mathematic guy know compute projection solve system use norm picture mind work mean mention time estimate estimate head situation notation patter analysis course compute minimize length vector vector length vector range matrix look vector vector look vector vector term norm projection range matrix vector vary value range value vector range compute difference vector vector value difference vector length vector range matrix picture mind compute care root argmin operator matter minimum affect end discussion root sum residual write term product write term product length beginning lecture use abitur knowledge rewrite product term component component end equation mistake form transpose matrix time transpose time value look intercept offset minimize function function choice function look minimum find compute crossing gradient function solution infinity infinity look function end function case find minimum minimum compute crossing gradient compute hessian look hessian check function look formula case happen motivate geometry mind look equation compute gradient regard break thing component stuff look cook book stuff formula matrix cook book confirm result achieve purpose life reproduce result generate use result gain result set equation transpose time transpose matrix invert assume column probability experiment case write estimate form write form norm work form engineering mathematic course thing work form need procedure solve optimization think audience computation numeric find matrix condition condition number matrix idea compute inverse transpose method apply solve estimation problem s.v.d. situation choice problem solve accept formula practice use use s.v.d. compute inverse inverse inverse break power minus inverse inverse read term literature remember inverse value decomposition express cross cross mean inverse power minus write way explain transpose inverse write sigma sigma compute inverse value value write denote matrix compute value decomposition change interchange element compute inverse value remain inverse method compute follow idea year watch refresher video minute value decomposition inverse detail tschebyscheff regression find literature tschebyscheff regression compare square square regression tschebyscheff regression use infinity norm norm want solve follow optimization problem minimize regard vector term infinity norm want residual maximum component imagine compute know derivative gradient crossing work let year year time people problem solve time year year people idea approach solve happen year optimization problem solve map optimization problem rewrite term programming solve point method hear point method explain week find balance theory pattern recognition application load optimization mind look problem pattern recognition people sit year year solve time search solve time answer manage map optimization problem explain detail mean minimize minimize scalar vector problem ask question want mean answer question know come point method use method lose method point method s.v.d. know use care principle use know work idea vector vector scaling factor blow vector want find scalar scaling factor scaling factor residual boundary change look boundary scale unit vector unit vector vector press solution idea minimize constraint constraint optimization problem example issue pattern recognition minimize map optimization problem know know solve solve norm use optimization problem let look norm story read literature read paper year find know people try use argue know compute gradient know solution kink compute derivative know forget measurement norm work use norm thing change map optimization problem norm mean vector component consider consider value component add express term optimization problem let use vector scaling factor component vector want difference vector vector vector unit vector scaling factor want wanna catch maximum want component want look solution minimize sum component component component guy christian point write way symbol obscure structure look component look component component residual fix print slide tonight look look mankind million year find decade happen read pattern recognition patter analysis book literature let year find situation deal switch norm solve problem instance solve system equation use norm start field image processing pattern recognition compress sensing compress sensing workshop duke university february year compress sensing solve equation base norm instance reconstruct signal nyquist sampling theorem violate assumption start area research compress sensing hype hype community solve know problem pattern recognition write headline paper compress sensing approach image filtering application paper accept theory know map problem problem replace know norm norm solve link reading mean sit browse try understand mean come idea research start know people notice thing field try find application solve feeling frontier research fact let look regression define optimization problem regression consider instance want minimize term norm instance system determine want solution unit length constraint norm solution picture mind mind unit ball forget square power solution hat compute solution norm solution violate constraint compute level set level set point figure point vector fulfill constraint unit length look optimization problem lasso introduce tibshirani community mean idea guy guy follow idea residual measure solution measure find solution minimize length insist unit length unit length norm solution lasso search web lasso find ton paper idea express situation look unit ball remember type unit ball solution leave solution increase hit unit ball solution unit length norm resolution term norm draw figure case hit kink unit ball turn solution solution number element idea lasso norm combine norm solution number component solution revolution lasso come look solution number entry number entry run optimization problem complexity blow complexity blow expect detail mean teach class optimization constraint optimization business try teach want bring track intuition optimization problem work use pattern recognition pattern analysis idea ask detail regard thing exam idea know detail look reading find thousand page thing explain regression norm lasso norm mean come guy replace norm norm guy reference thousand time people idea guy professor stanford let decrease mean kid idea idea line research note think circle ellipsis use norm norm case idea stefan fact sensing mean teach course compress sensing idea compress sensing work work chapter motivate regression regularizer assume measurement require estimate parameter vector happen determine system equation mention determine system equation solve need vector bar support mean number entry care vector entry vector vector vector recover case recover use optimization solve constraint optimization problem minimize norm equality identity believe know constraint optimization problem generate research field people world work image processing computer vision find method perform know yes lab work compress sensing think use computer tomography application research project compress sensing solve problem consider lab future sensing norm identity constraint guy think game thank attend tomorrow encourage come
welcome tuesday tuesday session minute try chapter norm learn network year network idea use application program picture jump discuss norm talk norm norm norm norm norm norm look norm failure homogeneity criterion literature norm add sentence norm norm wikipedia mention thank pointer talk norm look unit ball unit ball picture mind optimization chapter consider day lecture unit ball infinity norm remember norm circle norm diamond know use norm regression line fitting know difference norm wave research consider norm solve problem image processing conference focus topic use norm solve regression problem context compress sensing feel read browse web regard compress sensing find ton paper year norm optimization point problem solve burn shell brain norm form solution period form solution norm form solution norm optimization problem norm optimization problem inequality sign remember criticism mean component inequality hold component difference vector component component motivate remember solve optimization problem use norm norm form solution solution people engineer use norm approach case norm term robustness combination christian candidate seat sit sit microphone build mixture intuition look penalty function idea follow idea follow consider norm consider norm remember norm norm operate value associate cost value cost consider instance penalty function know value norm start penalty value norm association picture value square look function behave function tell cost associate value leave zone cost cost function induce norm value type cost pay deviation look optimization problem residual component sum residual cost think example think follow point want line fitting want find line accumulate distance point line minimize sense residual point choose regression parameter distance point line minimum way fit line use norm step use norm use penalty function look norm function operate component vector want minimize cost imply penalty function apply component fact residual difference vector consider instance phi phi norm estimator compute parameter line slope intersection accord optimization problem use phi norm got know norm norm think shape function shape function future work talk instance support vector regression introduce penalty function tell norm information phi function phi function optimization problem optimization problem solve tell function attend lecture optimization function function function idea girlfriend explain thing girl derivative mean run life research tell happen happen case happen accept belly rex like recording translate maedchen bauch konnkav conversation pardon read version trick talk function set talk set know function set bauch rex konvex belly rex set point connect line element line set instance set point connect fall set function definition definition naive check definition set life thing need know function draw epigraph point area function epigraph epigraph epigraph set function epigraph set function attend room lecture invite talk let look follow function draw function blow room function mean guy want tell maximum function maximum minimum let turn let look function mean minimum minimum fact know epigraph connect fall function function function negative epigraph brave maedchen turn need know math lecture function definition care point function look set got optimization problem require function constraints phi optimization problem optimization problem imply problem click penalty function look penalty function play role pattern analysis note penalty function phi assign miss cost residual assign cost residual phi function penalty function approximation problem optimization problem watch video introduce guy want write evaluation guy explain thing equation measurement world error residual error phi tell guy error pay money norm tell guy color lecture mean norm associate cost element norm penalty value norm norm pay know grow pay norm optimization outlier outlier weight pay outlier norm norm pay deviation course impact way instance regression line set point penalty function like know like penalty function penalty function instance type penalty function penalty function let look penalty function use pattern recognition plot draw figure copy note understand know deviation weight deviation weight intuition lock barrier function guy explain lock barrier function lock barrier function play role point method constraint optimization instance express accept solution look function lock know value run singularity lock barrier function tell line penalty infinity violate constraint application need lock barrier function lock barrier function property mean look case look draw pay infinity penalty solution border point value function log barrier pen penalize deviation way norm penalty increase penalty irritate value range lock barrier function engineering problem lab need lock barrier function know inequality maintain optimization process inequality lock barrier function use term function interval idea know day sit read think idea come idea guy literature look literature year year talk idea attend lecture know thinker lecture people teach way thinking leave track know start think professor think know track think know border thinker field know problem solve come solution let look look zone penalty function zone mean function look function look follow zone penalty function value function function interval range penalty norm norm increase penalty zone accept point zone weight interval care penalty function instance case zone think instance happen zone penalty function point stripe point stripe contribute penalty point stripe induce penalty zone optimization problem end optimization problem function draw epigraph line epigraph case function function plot function look epigraph function function variable check intuition engineer math department need knowledge money money generate knowledge solution variable fix vary look graph dimension impression probability miss point miss point look section function check turn function slice function engineer try let happen record allow build thing system know approval stuff know slice check epigraph save prove prove error penalty function mean error penalty function function know follow let look follow regression problem know measurement engineer measurement engineer use use norm guy penalty bring solution direction cause bias school engineer happen know bunch outlier know impact engineer work reduce notice classify engineer want measurement weight meter meter care know zone zone weight error probability penalty function function point constant forget fact function turn epigraph purpose write thing think example epigraph line fall graph mean optimization problem optimization problem fall category problem conclusion avoid engineer team wife economist know watch video know husband day kid mean perform computer scientist perform student perform student find place gaussian gaussian gaussian gaussian mean covariance matrix stuff mean know hoover function dean huber relate huber function guy professor university bayreuth statistisch know mean know statistic guy statistic year understand motivation type function know engineer people economy manager know pain neck use function use function run optimization problem ask penalty function function look guess kink continue point line point line norm interval norm type norm benefit norm benefit norm benefit norm term deviation weight benefit norm variation weight penalty function idea mean function accord guy mean invention know science function use norm norm penalty function feeling publish paper think penalty function experiment set case compress sensing approach paper publish climate community strategy work field day come publication learn attend learn consider vector matrix norm matrix norm watch video vector norm infinity watch video unit ball got idea talk regression norm optimization problem require solve range form solution case estimator problem use instance infinity norm use regularize regression use residual try minimize length solution term norm norm norm form solution point work work form solution mix instance norm programming problem christian idea work learn lecture explain care know optimization problem thing knowledge lecture need know need know basic algorithm constraint optimization optimization fear guy stage come slide explain constraint optimization optimization hell justify motivation feeling theory kill feeling feeling need know fail sense mean know book read book record book buy book shelf work matrix computation book look mean sit read book mean kill information book record mean book look matrix property information read sit read book begin page use book teaching purpose guy gene golub die year stanford professor computation know computer science department car plate professor s.v.d. web reinvent s.v.d. rediscover s.v.d. seventy prof s.v.d. plate book reference time book write accord course bau trefethen year year book like read read read catch point buy student book mean mean book find web way web buy book page page find information optimization book write stephen boyd stanford professor lieven vandenberghe engineer engineering access optimization lose know compute derivative bound happen end day know use access theory read book like point sensing topic day recommend browse web bit play bit look researcher type problem address find section norm basis understand paper know guy thing application follow core idea consider link kind motivation know water feel pattern analysis check read page feel generate feeling life question christian think happen think mean guy deal signal nyquist sampling theorem violate direction read hear optimization problem norm ask happen use type norm know complexity problem change guess switch mean people blow room question use norm mean find close form solution robustness use infinity norm know know unit ball change thing blow room blow room rosenblatt perceptron rosenblatt perceptron invent day pattern recognition machine learning time bear time rosenblatt think stuff let talk need motivation story pattern recognition define function minimize function remark result look lesson learn check read detail present theory motivation function minimization discussion lesson learn reading mean way patter recognition work let look motivation mean thousand way hold second think run time care continue mean class let feature class feature class way compute separate function decision boundary method version week version problem ton approach consider problem compute decision boundary idea follow idea compute need estimation norm stuff optimization procedure compute gradient assume class mean exist line feature class feature class class reason want compute separate hyperplane accord follow idea class let draw line misclassifie point want find algorithm compute decision boundary way distance misclassifie feature feature vector minimize iteration ask question decision boundary distance point line minimize idea sir end function value beginning mean guess line start line look know error find iteration step reduce error reduce error reduce error end separate hyperplane class converge converge homework think function look function question sit try formalize function allow use norm compute distance hyperplane thank monday
welcome monday morning session morning sketch picture lose story line dig learning algorithm year principle pattern analysis machine learning rosenblatt perceptron extend proof algorithm converge sketch proof understanding pattern analysis summer semester model estimate probability class feature vector consider regression method model probability use sigmoid function remember shape sigmoid function look step function representation probability read sigmoid function decision boundary look modeling probability use follow factorization class density function model class density function way instance use gaussian implement gaussian classifier base assumption look classifier find decision boundary talk bit datum normalization datum stuff algorithm know pattern recognition winter semester section combine reconsider concept algebra s.v.d. type normalization week lecture norm norm approximation overview norm vector norm matrix norm set minimization problem estimate parameter deal similarity measure similarity measure base norm type norm hamming distance know information theory norm sum value norm know norm use norm set optimization task infinity norm norm bunch norm look unit ball relate problem look constraint optimization remember ridge regression consider ridge regression lasso tibshirani lasso consider use norm combine norm bound length vector degree freedom point patter recognition pattern analysis research usage norm topic algorithm algorithm bear idea replace norm norm solve correspond optimization fact norm community relate fact optimization theory progress year optimization constraint optimization problem solve use point method hear introduction follow lecture picture consider decision boundary class classification problem type question pattern recognition application class understand concept think class problem set training sample find number decision boundary way compute decision boundary look rosenblatt perceptron network type approach compute decision boundary way compute think present method lecture presentation software let talk structure let motivate perceptron dig want compute decision boundary problem change assume class mean set feature set feature belong class find function split space class feature misclassifie set find function splitte percent idea follow map estimation function regression problem audience set regression problem estimate decision boundary rosenblatt come follow idea know time compute separate function decision boundary way minimize distance misclassifie feature vector decision boundary iteration step mean think follow situation feature vector instance guest guess decision boundary color monitor beamer misclassification misclassifie object distance decision boundary try find decision boundary iteration step distance misclassifie point decision boundary reduce iterate hope end decision boundary idea need function function measure distance misclassifie point decision boundary need function assume follow class problem assume denote class number case class number yes class number class number yes color color let red classify associate integer class advantage calculation decision boundary function feature vector plug function sign distance value learn unit length sign distance value tell distance decision boundary sign tell decision boundary sign function apply result plug feature vector decision boundary class number situation decision boundary know vector sign distance point value look sign class number decision rule use sign function plug vector function function number decision boundary advantage choose minus course rewrite thing reason decide use idea rosenblatt use idea rosenblatt want minimize distance misclassifie point come follow optimization problem minimize function degree freedom alpha alpha parameter line define set set set point set point misclassifie situation point form set set misclassifie feature vector sum misclassifie feature vector sum sign distance measure distance class class classify situation look feature vector misclassifie sign sign classify classify look misclassifie point feature vector thing term term minus thing want minimize distance want minimize distance point decision boundary function let discuss function mean engineer solve optimization problem let discuss problem function idea jens think push blood pressure bit let think mean engineer agree study thing like like like teach french dislike dislike thank develop intuition problem let let look point hold let way matter mistake mistake estimate step feature vector classify mean cardinality cardinality change iteration learning method cardinality number optimization problem include set change vary iteration want set type optimization problem consider regression problem variable compute gradient crossing gradient mean flexibility function allow use optimization idea apply look gradient rosenblatt think mean change iteration use decision boundary function change change change change look gradient function know look let compute gradient compute gradient let compute gradient summary discussion element sum function depend include misclassify include misclassifie feature vector iteration step cardinality change remember figure cardinality variable compete variable parameter alpha cardinality mixture optimization problem direction minimize function compute gradient compute gradient remember definition function alpha transpose alpha sum sign alpha alpha vector compute derivative regard parameter alpha happen element include alpha derive regard alpha survive compute type derivative ranjeed work homework problem derivative regard vector alpha mean read derivative regard alpha alpha alpha alpha look vector derivative know compute vector derivative matrix cook book course course look term compute derivative regard component alpha task need matrix cook book cook book find sum element gradient look gradient function look use element gradient function sum find update rule estimate decision boundary fact consider problem want update point want use point feature want update thing point feature find step iteration scheme rosenblatt find look follow want update step visit point misclassifie point step step situation let line point point walk point point update decision boundary idea wanna update point update decision boundary update rule iteration step define follow element gradient sum element gradient sum point pick correspond point consider misclassifie point update estimate intercept estimate norm vector vector add gradient component alpha gradient component alpha correspond feature vector motivate gradient course scale thing step scale bit step forget scaling factor implement perceptron update rule mean use training feature feature use decision boundary draw decision boundary draw iteration thank look misclassifie point start use selection think strategy use alpha alpha christian jochen jochen initialization update alpha alpha use value misclassifie point function look instance choose misclassifie point update type iteration scheme mean update alpha offset line class number minus num update misclassifie point vector weight class number look look miracle work algorithm look implement exercise training set feature vector class number instance distinguish letter handwriting letter feature vector compute assign class number sample group write letter collect information training set label feature vector follow iteration iteration index start set alpha vector alpha start function function feature vector let start function apply follow iteration scheme select pair training set look mean feature vector decision boundary misclassifie class associate class misclassifie product class associate misclassifie thing know point misclassifie point misclassifie row set update alpha alpha alpha alpha way characterize line estimate norm vector hessian function offset use class number product class number feature vector add iteration step increase iteration index select pair look misclassifie misclassifie update state algorithm converge repeat loop terminate iteration scheme end decision boundary algorithm motivate gradient computation forget sum look point find algorithm look algorithm converge believe set feature algorithm converge estimate kind gradient method converge implement result time learning algorithm learning algorithm find decision boundary separate honour algorithm converge think convergence proof lecture mean teach pattern recognition pattern analysis convergence proof follow think thing read literature situation think look detail convergence proof algorithm remark update rule mean update rule update rule happen classify iteration require guess decision boundary beginning happen algorithm behave parameter alpha decision boundary observation combination feature vector mean look alpha combination feature vector weight alpha vector line combination feature vector combination feature vector repeat decision boundary look mean look happen iteration alpha combination feature vector multiply intercept sum class number sum class number set set index require update line look index use update line algorithm alpha combination feature vector intercept offset decision boundary sum class number rewrite bit factor product write way weight sum product feature vector observe use training multiply observe feature vector want classify alpha determine feature vector set misclassifie vector training procedure course result depend initialization start function look initialization algorithm determine feature vector misclassifie misclassifie learning procedure think insight story feature classify care pattern recognition people feature vector cause trouble feature vector decision boundary feature focus feature decision boundary care classify stuff decision boundary result think hope find algorithm converge converge ask exam decide mean decision boundary depend initialization number iteration initialization set happen algorithm converge run cycle detect problem constraint tell use algorithm practice understanding understanding convergence training algorithm watch video observe know jump time type teaching arm know video colleague teach time style life bishop joke guy listen like plan drop loose semester start lecture video leave lecture middle semester lecture chance follow lecture miss strategy way story look convergence proof like collect argument require thinking lecture convergence theorem rosenblatt novikov novikov sign war know american russian find time find time time know mankind know thousand year year people place find stuff happen time tell know assume element training set find row row means term geometry mean term geometry forgot jan lars forget jens read term geometry scale line mean picture draw mean pattern recognition know class deal class horizon line alpha star alpha star plug value tell value tell tell plug value let instance plug value number number tell distance distance line sign distance classify sign multiply class number thing decision boundary misclassification term value value distance point decision boundary value row mean exist row define stripe feature vector mean stripe width row feature point yes stripe interpretation feature set class decide class exist row row point decision boundary mean come decision point formalization prerequisite define beginning lecture want feature set look jens interpretation got trick mean lose formula build picture mind carry formula brain know figure walk theory require research use vector unit length matter rewrite function way factor vector unit length constraint requirement value distance value scale distance value know algebra set constraint prerequisite formulate hour minute set state follow perceptron learning algorithm summarise slide converge decision boundary iteration bound follow value alpha intercept square length simone tell correct norm use norm set feature vector feature vector compute length feature vector term norm length feature vector length feature vector set training sample measure length feature vector look feature vector term norm divide rho square divide stripe intercept length feature vector divide wit stripe number iteration require estimate estimate decision boundary result learning theory tell iteration require learn decision boundary implication bound depend dimension feature vector space space matter need number iteration dimension feature result prove prove mean bound algorithm converge need number iteration algorithm terminate repeat loop vector classify prove let alpha star alpha star point estimate dimension vector jens vector look definition line alpha line dimension feature vector dimension vector pardon vector characterize decision boundary estimate iteration iteration compute product think term vector star vector iteration compute product mean term geometry mean project vector vector scaling factor interpretation interpretation look consider bound bound product look bound product factor statement find row number iteration iteration number iteration step row wit stripe wit stripe consider let proof compute let algorithm know iteration know feature vector misclassifie update alpha alpha alpha time misclassifie feature vector definition update rule iteration scheme know product rewrite thing way vector time vector time read jens mean geometry mean number time alpha star transpose alpha star definition product week mean distance distance distance row write row inequality row interaction step plug thing step iterate initialize situation alpha alpha time row bound estimation length time row project vector point view bound increase iteration step increase row row know class sense bound length look bound look bound know thing converge choose accord term bound meet bound idea proof like apply schwartz inequality schwartz inequality tell tell idea schwartz tell vector compute product time erase thank hint buy software tell matter inequality schwartz know know bavarian abitur grade class semester china learn schwartz hear zhing fung chang fang inequality mathematician know russian mean inequality hear inequality principle look scalar product scalar product apply schwartz length vector time length compute length write root alpha star square write write constraint theorem state alpha alpha alpha square alpha alpha square sum norm require root scalar product bound bound bound thing like bound contain length estimate consider reorganise estimate compute estimate let look norm vector factor parameter hyperplane use classification look root look square rid root formulate apply update rule apply update rule alpha compute use alpha read algorithm norm vector square sum vector way transpose time remember day multiply thing multiply transpose transpose transpose transpose class year bavarian abitur learn thing vector vector vector learn age case type joke balance sheet like remember remember length predecessor time mix component length update vector length consider let look write definition multiply equation know mean step classification result classification result mean sign sign write leave bound length vector component component write length feature feature vector training set argument argument forget mean iteration step iterate step factor look happen length vector length vector tell length feature vector length feature vector square length component vector case component square bound vector look thing thing know picture mind estimate iteration estimate want compute scalar product product scaling factor vector know bound time row bound square use schwartz find bound vector length alpha square look equation follow hold alpha star think habe got plug factor describe slide bound plug relate relate schwartz rework slide describe think let rewrite product product inequality length update vector multiply root term multiply root term multiply root term compute bound square square square need root build thing bind vector lower bound vector set compute square resolve equation state theorem yes tell bind tend alpha star square divide rho square square miss congratulation need fix let let read interpretation case need lot iteration need lot iteration decision boundary stripe know class find line change bit feature vector fall classify set decision boundary iteration need feature vector iteration need range feature vector tell scaling feature vector sense scale feature vector impact number iteration offset intercept charge intercept lot iteration iteration change vector alpha alpha characterize decision boundary look change use iteration scheme time iteration find bound bound find bound grow bound shrink bit iteration number identity bound proof proof effort mean idea set proof way mean think theorem result basis theorem learning theorem theory attend lecture learning theory basis lecture study year offer end learning theory lecture thing student student teach day learning theory let problem student like know prefer lecture know learn hand waving concept know lecture exist lesson learn slide learn function change iteration step situation function change number element sum change iteration step point view student exam draw type figure affect know people optimization problem kind mixture turn learning rule learning rule rosenblatt convergence theorem tell number iteration learning rule depend dimension feature vector result depend intercept depend length feature vector depend wit stripe class wit stripe concept use support vector machine learning week week follow week learn monday lecture mean teach read search web rosenblatt perceptron find wikipedia entry find sketch proof check book update rule guy find know read book ripley proof let way version proof read book mention time add list hastie book learning theory learning theory springer verlag publish think edition market thing sell book springer series statistic way book like attend lecture year book like favourite book buy way buy question know lot concept compute decision boundary know lot concept compute decision boundary class find method compute decision boundary question depend generalization property feature vector come training set classifier behave need study choice set decision boundary answer chapter follow chapter chapter muessen helfen komme praesentationsmodus thank idea point keyboard chapter let chapter know hear ton lecture thing learn student remember concept add chapter optimization learn lot optimization reason understanding optimization method stuff pattern analysis pattern recognition pattern analysis mean compute feature measure sensor sensor guy student build sensor signal compute feature vector know learn lot thing winter semester learn train adapt classifier observation training set define function optimize function learn decision boundary know optimization come function solve associate optimization problem need understanding optimization thing university course optimization optimization theory course algebra course statistic learning theory pattern analysis situation university find way explain concept follow concept pattern analysis point view refresher course know sit lean relax enjoy life run concept talk talk motivation optimization know type optimization problem consider talk optimization know happen talk support vector machine talk constraint optimization talk optimization look method method follow function direction thing change term function value method require optimization problem talk tracking line search armijo rule talk gradient method section method section mean gradient guy tell mean gradient point gradient point direction descent direction function change gradient know direction function reduce mean learn gradient decent thing gradient decent mean depend norm use gradient decent thing use norm direction gradient use norm thing change lot use infinity norm thing change lot use thing change optimization use norm inverse hessian newton iteration scheme think mean newton iteration scheme learn gradient decent multiply gradient matrix matrix change direction gradient tell thing tell thing believe lesson learn summarize fact optimization optimization problem deal optimization solve optimization problem solve algorithm talk method relationship gradient method affect selection norm learn norm set function view thing thing use norm algorithm accord method winter semester coordinate think idea follow coordinate direction use norm direction hope understanding optimization routine library optimization method use minimize function motivation optimization problem solution pattern recognition pattern analysis machine learning intelligence deal signal learning system need kind optimization search optimization phase need know optimization method optimization class method algorithm use lot pattern recognition gradient constraint optimization programming programming optimization thousand method pattern recognition people equip basis mean study optimization theory semester patter patter recognition understanding concept find situation handle optimization routine work know colleague ask build optimization algorithm problem summarize lecture write book pattern recognition patter analysis refresher course optimization technique write book apply pattern recognition chapter optimisation think rank book lecture lecture learn optimization course life matter taste researcher people use optimization use algorithm mean find example algorithm work algorithm understanding find optimization scheme solve problem way sell method sell software million dollar purpose work publish rank paper idea optimization routine review math know check work know experiment datum datum work method use work prefer library image datum basis datum read paper capture image end camera recognition rate percent find image algorithm work datum search base algorithm fix algorithm search base datum algorithm work find combination web library people compare algorithm talk optimization tomorrow minute slide know slide minute slide minute convergence film movie care thank gut
welcome monday session hope enjoy weekend support vector machine value decomposition s.v.d. use talk support vector machine continue topic support vector machine reconsider picture lecture know pattern analysis teach lecture parallel switch pattern analysis modeling probability issue vector winter semester sequence feature sequence vary length length set feature vary cardinality degree flexibility feature feature use fight problem vector fix dimension dimension feature vector denote state talk classifier beginning role pattern recognition learn cost function decision rule maximize probability turn provide classifier talk approach model know scale probability probability class approach model class instance talk base classifier idea base base steve base require decision boundary case base provide decision boundary core assumption base mean factorise way decision boundary depend choose component product gaussians instance degree decision boundary class share variance decision boundary feature feature vector set feature vector dimension feature vector tell boss money build classifier work classifier base feature vector buy build base classifier base feature start classification business pattern recognition mean require independence assumption mean feature vector component provide feature vector probability independence assumption fulfil work strategy feature vector feature vector provide component apply advantage bring feature vector feature vector know dimension problem explain curse dimensionality way detail advantage feature turn decorrelate thing apply thing exercise component feature vector component type distribution follow gaussian sum combination variable know gaussian thing reduce dimension beat curse dimensionality thing decorrelate component base job know feature component gaussian apply classifier use base idea feature component model gaussian understanding think people idea pattern recognition work mean feature try neighbor classifier work curse dimensionality hear distribution apply work know theory underlie know work base talk classifier talk classifier class density model requirement component feature vector classifier look decision boundary degree decision boundary covariance class class parameter tying class share covariance decision boundary understanding probability probability probability decision boundary feature offset decision boundary left right probability way model probability context regression set slide explain relationship regression function probability learn write probability base decision boundary line instance hyperplane tell decision boundary write probability associate think support vector machine question exam explain support vector machine work explain idea margin write optimization problem end core idea pattern analysis lecture find probability write support vector machine associate associate probability know regression power minus formula describe decision boundary write impress write know gut gut talk transform talk dimension reduction dimension need number class relationship number class talk component analysis talk norm talk vector norm talk matrix norm talk estimator want estimate instance regression line use norm form solution use norm optimization problem learn norm norm matrix know learn unit circle norm point result research field pattern recognition pattern analysis base consideration norm replace norm reason jump look norm deal optimization method norm norm prefer prefer norm tell problem point compute regression line people thinking work norm work norm learn norm know explanation pardon understanding know use norm understanding math wanna interpretation think motivation close form solution mean norm compute derivative compute point derivative vanish turn norm know point compute derivative point gain lot problem switch norm handle optimization problem problem solve norm talk norm talk bit optimization talk optimization explain gradient method method relate method gradient method use norm prefer norm use stuff learn semester deal method coordinate decent learn winter semester norm use norm norm look unit ball project vector direction chapter consider support vector machine let reconsider idea way bring page idea support vector machine machine margin situation thing remember theory rest mean derive idea mean feature vector space feature let use colour let use colour feature figure figure paint draw ask explain support vector machine mean know know way come decision boundary draw decision boundary provide method compute decision boundary question mind decision boundary generalize classifier base decision boundary estimate classifier generalize mean generalization property mean classifier behave observe feature vector training set feature use compute decision boundary training feature feature come check classifier provide decision generalization property tell superstar world following use training set feature estimate decision boundary use feature check system generalise situation people come recognition rate percent attend conference tell recognition rate percent thumb tell look use set training testing course tell check code happen year find image speech signal classify select set datum use check generalization purpose yes kid tell experience question pattern recognition people face find know strategy find decision boundary point idea vapnik compute line decision boundary way wit tribe feature fall wit maximize maximize wit know wits alpha alpha vector vector define hessian decision boundary assume function evaluate point evaluate point week compute line alcohol weekend typo alcohol look compute decision boundary boundary solve follow problem want maximize use formulation use want want maximize term minimize optimization problem subject constraint guy constraint constraint alpha transpose alpha time constraint decision boundary value value feature element class value class number thing thing element class class thing write alpha transpose alpha know function constraint solve solve topic todays lecture ask exam think point sale knowledge draw figure explain optimization problem point feeling dig detail switch chapter page switch chapter know convince affect grade rumor ask question rumor grade mean fail attend lecture chance fail survive deal optimization problem jochen like optimization problem know solve solve optimization problem constraint problem constraint mean chapter optimization point view come chapter optimization come pattern recognition topic start work constraint optimization problem feeling optimization constraint optimization refresher course optimization find way deal constraint optimization problem deal question question mean look know mean course evaluation choice grade tell time grade matter talk optimization optimization duality problem lagrange multiplier method hear education system regard optimization lagrange lagrange multiplier method math course engineer mention know solve talk talk problem problem consider talk lagrangian lagrange function lagrange problem learn slater condition optimality condition hear reading chapter lesson learn miss forgot headline guess mean learn lecture lesson learn year omit tell student check condition find follow learn round exam people fear ask ask function feeling understand decide lecture detail regard constraint optimization constraint optimization procedure mind beginning lecture optimization technique effect research activity thing think work field want contribute science let talk problem type problem consider follow optimization problem optimization problem consider follow assume formulation want minimize function term minimize slide web feel copy listen function optimise constraint consider class constraint inequality constraint equality constraint equality constraint function equality constraint talk optimization problem explain detail restriction require function function want minimize want compute minimum function point want find point fulfil constraint point fulfill constraint point point fulfill constraint solution problem point fulfill constraint solution problem point mean constraint fulfil look sir mean typo typo thank pointer mark function want minimize constraint instance instance require solution interval constraint tell minimum look constraint boundary interval boundary map optimization problem consider formalism optimization problem consider want minimize alpha norm alpha time decision boundary evaluate consider point condition inequality condition equality condition look support vector machine norm discuss look want think problem know engineering math constraint optimization problem incorporate constraint function idea lagrange multiplier method constraint extend function use constraint multiplier tell engineering math sum unknown constraint function weight lambda lambda professor tell multiplier work work derive compute crossing solution solution think explanation know know talk define definition function mention problem minimize function equality identity constraint lagrangian problem define follow function point video function mean function inequality constraint thing equality constraint weight lambda lambda select way select way penalise people tell optimize function function lambda collect vector vector multiplier vector math literature variable variable incorporate constraint function weight lambda penalty term value fulfil constraint pay penalty idea work use multiplier method solve constraint optimization method consider detail follow let look lagrange function look solve problem introduce variable variable lambda variable dimensionality problem increase function following try eliminate try eliminate statistic know eliminate density function know eliminate marginalize integrate want lambda marginalize look value lagrangian achieve change value definition lagrange function alcohol sound explanation alcohol know guy lab lab beer rumor truth lagrange function record guy watch lagrange function lambda lambda variable introduce compute infimum function regard math student know steve inf stand informatik dibble inf explain mind replace inf min work know minimum minimum replace inf min mean simon look dibble inf simon mean joke watch video find joke guy tell joke min simon minimum diploma minimum diploma joke let cancel record worry replace min understand mathematician kill hand wave mathematician mean think look definition function inequality constraint equality constraint guess mean write mean maximum right maximum inf sub worry replace min max come understanding write note look function function point point compute minimum point affine function variable forget function affine function intercept point function variable point affine function affine function engineer engineer function life deal function thing prove function function infimum mean mapping affine mapping infimum computation maintain lead function lagrange function function mean function function allow minus function explanation minus function connect point epigraph guy tell come lagrange multiplier use infimum operator function function point affine handle end function suppose check use theory function read book boyd read chapter instance function feel convex constraint framework come solution constraint optimization problem thing lagrange function provide bound optimum function look minimum look function lambda estimate estimate value value bound function value minimum mean study situation bound value function look follow lemma star value optimization problem value optimization problem mean star star value star value lambda vector lambda component constraint sign follow bound value function value star value lambda function function function study want proof want proof think proof thing need know proof multiply number number number multiply number mix sign result core knowledge math need know proof let look proof course proof let assume point optimization problem mean point steve steve watch video let check point record fulfill constraint fulfill constraint fulfill constraint mean mean tilde fulfill constraint mean tilde value number point mean argument come lambda symbol tell component lambda multiply think thinker multiply number number add use lagrangian consider point lagrangian look function want minimize constraint point course sum number course tilde point mean let look lambda infimum point definition miss point point star proof star solution lambda function star yes solve constraint optimization problem write lagrangian evaluate lagrangian lambda fulfill know function point let look lagrange problem want bound value look lambda fulfill constraint lambda select number function look function function star mean set optimization problem want maximize function constraint lambda need sign fix slide consider problem find bound problem lagrange problem set want maximize lambda constraint lambda solve constraint optimization problem write lagrangian compute infimum variable want optimize function gain bound function value solve problem come come solution optimization problem value check lagrangian sense guy sense witness function duality gap duality gap mean duality gap look want optimize function let situation value function value star lambda select lambda know function value star value value choice lambda look lambda distance distance want maximize value star yes star star duality gap duality gap solve optimization problem star star know star difference difference duality gap optimization problem duality gap mean optimization problem problem solve solve problem optimization problem duality gap star star solve optimization problem solve optimization problem problem point percent case duality cap gap behave way want kind problem deal pattern recognition let way mathematician think deal problem duality gap case consider duality gap check slater condition discuss second got idea function want optimize function function know minimum constraint look bound function function happen probability mean bound infinity bound infinity mean statement know bound function value look minimization problem tell minimum bound infinity mean value statement theory cover situation definition duality gap let star value problem star value lagrange problem solve describe optimization problem difference star star duality gap read pattern recognition book people argue duality gap picture draw slide star star mean conclusion duality gap star star difference duality gap mean statement prove case talk duality duality gap talk case duality primer problem problem duality duality gap turn inequality hold duality yes duality duality slater condition load constraint optimization slater condition optimization problem inequality constraint mean identity way identity constraint constraint identity constraint constraint function function duality hold slater prove prove optimization problem minimize mean function mean consider epigraph set function connect point epigraph function want minimize subject forget complain handwriting evaluation find color simone need fix identity allow duality hold optimization problem function sharp math identity know inequality identity duality hold mean duality hold mean duality gap duality gap optimization problem duality gap computation mean reach lose duality condition karush tucker condition look karush tucker condition kuhn tucker mathematician karush student master student come result master thesis condition master thesis project contribute research master thesis let follow let look star lambda star star mean star lambda star lambda star star star point problem problem minimize constraint solution solution star point denote star look problem compute lambda remember lambda lambda value lambda star star know lambda star star star duality gap value function star tell star lambda star star evaluate star lambda star star result value trust cheat point view compute solution check solution optimization problem evaluate function function value check function value gap gap duality gap situation instance slater condition fulfil witness function witness function lambda star star witness function duality gap situation star duality gap point know gradient vanish mean solution gradient vanish point compute lagrangian lagrangian compute derivative regard evaluate function star lambda star star course vanish condition condition karush tucker condition condition gradient vanish mean thing compute lagrange function gradient vanish solution look insight fulfil condition check constraint fulfil vanish check constraint constraint problem lambda slackness require lambda proof require fulfil way mind slackness slackness karush tucker condition require point margin define support vector machine come minute require require slater condition fulfil talk problem slater condition fulfil chapter lambda way require product require idea scalar look situation duality gap mean sum nabla lambda star star want star mean mean identity slackness product vanish function gap duality gap matter lambda condition gradient condition constraint constraint problem need slackness fulfil gradient lagrangian convexity hold star lambda star star point condition hold condition hold optimization problem solve context support vector machine problem know point condition fulfil summarize lesson learn learn problem problem duality gap learn slater condition condition fulfil function satisfy function consider point star lambda star star know lot information guy hour sit read textbook recommend lecture read understand multiplier method work handle handle constraint optimization problem appear context support vector machine instance let chapter support vector machine question jochen know talk talk algorithm use library attend lecture optimization let let optimization problem optimization problem solve margin situation margin situation variable theory problem insight theory focus type optimization problem function situation function function constraint theory discuss minus plus change way consider training datum pair feature vector assign class set training feature consider reconsider optimization problem come solution lead margin solve problem find decision boundary stripe feature space feature lay stripe start lagrangian start lagrangian lagrangian include slack variable lagrangian slack variable think morning slack variable lagrangian alpha norm vector intercept slack variable lagrangian vector inequality constraint vector variable compute derivative check optimization problem optimization problem check karush tucker condition karush tucker condition hold mean derivative vanish compute derivative regard alpha regard alpha let look function compute derivative regard alpha derivative regard alpha jochen alpha transpose alpha alpha derivative regard alpha forget derivative regard alpha component need consider sum lambda transpose time alpha alpha transpose derivative regard alpha sum come use matrix cook book thing mean look lambda alpha constant component know vector sum alpha lambda solution solution optimization problem alpha combination feature vector alpha norm vector decision boundary combination feature vector prefactor depend multiplier class assignment training datum let let want teach german guy reason forget want conclude alpha norm vector decision boundary combination combination feature vector perceptron motivation situation fact mean know feature vector determine line combination kind derivative regard alpha question regard limit regard lambda bring limit bring limit derivative regard alpha alpha compute alpha tell lambda class assignment class class combination class assignment weight lambda alpha combination vector feature vector class number combine combine lambda turn derivative compute derivative regard variable consider detail result define alpha let look wolfe dual wolfe dual function look margin situation function constraint constraint alpha function detail simplify thing bit look look term rewrite instance switch alpha transpose thing change rewrite sum term lambda transpose time alpha plus bring sum lambda alpha constraint lambda suppose weight sum class assignment karush kuhn tucker condition solution suppose look thing die let look come lambda lambda alpha transpose alpha transpose write sum term alpha transpose alpha alpha transpose alpha half time alpha transpose alpha half miss function function fix version lambda step use identity alpha sum lambda norm square alpha transpose alpha alpha transpose alpha replace alpha function function lambda lambda product feature vector product look tomorrow perceptron product feature vector optimise find duality gap solution find web thousand library solve constraint optimization problem know function karush kuhn tucker condition tell context thing want mention end lecture second leave slide function condition fulfil slackness remember stress point optimization chapter slackness mean product lambda function inequality constraint suppose condition hold mean start discuss lambda lambda alpha transpose alpha mean lambda multiplier select training feature know point lay stripe boundary stripe compute slap feature point feature point boundary know point lambda point mean point lay slap stripe consider define stripe mean point affect decision boundary lambda element boundary slap support vector come vector support decision boundary alpha combination lambda lambda care lambda non define alpha lambda consider point slap boundary mean norm vector line straight hyperplane define decision boundary combination support vector alpha combination support vector message thank tomorrow
welcome tuesday afternoon session minute topic cover minute speak overview continue discussion support vector machine change improve performance support vector machine context kernel kernel characterize concept use pattern recognition application idea worry discuss motive kernel kernel kernel function introduce feature transform feature transform feature transform apply feature transformation context instance feature covariance matrix compute datum use s.v.d. decomposition covariance matrix consider feature transform term enforce behavior feature feature transform context dimension reduction feature transformation thing thing consider gain advantage projection feature reduction feature dimension feature space gain advantage winter semester discuss problem curse dimensionality problem break thing feature learn sense bring thing dimension introduce concept kernel function kernel function use context support vector machine context perceptron smile destroy concept know talk way christian christian parent pay buck mean imagine talk bit kernel function type kernel function bubble miss item kernel explain week talk kernel book kernel lecture kernel calculus kernel teach semester kernel max planck institute tuebingen attend course kernel lead researcher field talk minute cover idea idea talk motivation kernel consider agree application application consider decision boundary consider hyperplane separate class guy talk pattern analysis restrict discussion class decision boundary break thing change life change decision boundary form discuss limitation mean concept solve use adidas shoe decision boundary case apply bring thing decision boundary problem consider practice datum class limit solve datum mean nature measurement start use sensor measurement datum case class datum run problem assumption weaken bit characteristic characteristic datum allow decision boundary formulation consider restrict datum need vector speech signal people speak speed feature dimension feature vector use summarize week learn lot feeling tell work use week start course evaluation mean learn method lift tool kernel method tool lift theory decision boundary solution problem consider change classifier discuss change know decision rule discuss look idea map feature space decision boundary job example bring thing space discuss mapping space life idea map datum feature space use feature transform use classifier use classifier use mapping feature idea think idea year concept classifier seventy level idea kernel thing use pattern recognition system idea year question slide need motivation come feature transform algorithm consider algorithm fix problem identify let look thing discuss lecture talk support vector machine decision boundary talk duality problem remember lecture talk lagrange function lagrange dual thing gap duality know remember come insight problem tell decision boundary alpha transpose time feature vector intercept alpha know alpha replace combination lagrange multiplier class assignment training datum replace alpha transpose jump sum sum look notice notice feature vector training problem learning problem training datum classify datum estimate decision boundary idea base idea want maximize margin function optimize feature vector measure term product insight tell point tell tell point remember product product let look perceptron happen characterize decision boundary perceptron decision boundary way replace capital decision boundary motivate regression capital slow alpha transpose alpha case perceptron look look slide rewrite alpha term combination prefactor class assignment hold offset intercept alpha class assignment set set set feature use adjust decision boundary look definition slide look term bring transpose rewrite bracket product decision boundary decision boundary perceptron write term product feature vector hold decision boundary support vector machine rewrite term product learning support vector machine write term product perceptron training algorithm write term product observe case consider feature vector term product conclusion feature pair term product transform feature mapping phi product transform feature product transform feature model kernel function idea transform feature consider product transform feature function define function tell system phi use kernel function idea minute core idea story tell brain burn shell brain method feature vector vector term product got email thank read gon fix problem describe email tonight tell type feature transform let look follow situation let look follow situation color color wanna firas blue blue blue feature class blue color want jochen use red red class steve color want come draw decision boundary class thank want send greeting friend video mom pay buck semester learn lot draw circle professor let try let assume circle radius support vector machine compute decision boundary idea margin idea follow decision boundary look jochen formula decision boundary square decision boundary rewrite rewrite instance alpha transpose plug value class value plug element class value definition circle plug formula circle vector feature rewrite term function rewrite thing term function define feature transform phi map instance support vector machine ranjeed color pardon red challenge bit mean blue green mean guy use white cancel typo remember follow use color ranjeed color color write phi phi product apply transform product apply stuff learn circle decision circle define decision boundary decision boundary polynomial polynomial circle polynomial define feature transform apply approach guy motivation feeling feeling use learn picture sentence tell tool learn feature transform transform lot apply idea look decision boundary perceptron use kernel perceptron way kernel kernel perceptron replace transform feature product transform feature instance look feature look class separate think transform feature space decision boundary work instance prototyping implement system draw decision boundary regression function decision boundary compute transformation build kernel base idea picture mind talk talk exam ask question regard kernel explain draw structure space dimension know ellipse sign consume beer example instance formula section ellipse parabola hyperbola choose decision boundary instance define transform square transform thing space decision boundary characterize section characterize section map decision boundary like like like like hate happen distance compute distance instance implement neighbor classifier compute distance mapping phi feature vector affect let compute euclidean use scratch talk distance bracket point use color pardon color disadvantage find correct register slide slide compute difference image ask simone solution mean distance product difference vector product transpose time consider vector multiply thing product time product mix term product prime prime transform distance transform space transform feature compute product example product phi come idea care phi product function prime function kernel function yes tell know software prime evaluate kernel function value transform product tell transform look idea kernel function rewrite thing term kernel function prime prime work use device kernel prime prime require phi compute distance function distance compute evaluate product feeling talk phi require transform feature transform phi build product evaluate kernel function feature transform slide write slide incorporate algorithm transform transform use product let talk kernel function introduce definition kernel function kernel function map pair feature number function mean prime prime think distance mean matter compute distance vector vector distance vector vector function map pair feature number define follow kernel function write term map mapping feature combine product kernel function combine product example example evaluation kernel function point view transformation feature product computation compute phi know algorithm need end day require compute feature transform product evaluate point evaluation kernel function computation transform feature follow product define kernel matrix let assume set know pair use training feature vector label class label feature course compute kernel matrix pair compute feature transform transform feature phi phi compute product component kernel matrix set feature pair transform compute product instance transform example circle transform feature feature compute product pair matrix matrix kernel matrix matrix kernel matrix feature select pair evaluate product transform feature matrix size matrix example steve kernel matrix kernel matrix property kernel matrix kernel matrix mean look form matrix definition definiteness look product let use feature evaluate product break component break component yes ranjeed break component sum element kernel matrix agree know component component transform phi transform phi compute product insert definition ranjeed agree look step product scalar value scalar value component component component definition look definition product sense bring index bring index look definition product happen sum component component summation variable bring sum sum product sum sum vector sum sum element sum sum renaming summation product vector argument vector mean term geometry length vector length vector length vector build kernel matrix transform feature feature describe kernel matrix argument kernel function specify phi like know kernel matrix component construct kernel function kernel function product phi transform feature mean question answer lemma tell kernel function kernel matrix rewrite kernel function term product transform feature message term mathematic write mercer theorem search web wikipedia result math mercer theorem tell kernel function indication engineering limitation function fulfill constraint look mean discretize version sum factor factor kernel function definition definition look formula component replace integral transform feature formula prove mercer theorem job colleague math function rewrite term product phi eigenvector eigen function construct define kernel construct kernel matrix know find mapping phi rewrite kernel function term product transform feature message let look kernel type kernel use mean kernel come kernel thing consider transform product compute product vector kernel use use product exponent kernel write use basis function compute kernel function norm difference vector divide variance use basis function use gaussian mean plug prime value kernel know associate kernel function rewrite term transform product mean care transform transform space care result kernel function transform space care space look define kernel use sigmoid function write term tangen think kernel use expectation use spline spline function kernel function question compute kernel function feature mapping phi kernel function write product answer mercer theorem eigenvalue decomposition lead transform look want look mean beginning teach semester course principle teach semester course kernel want kernel trick use literature read kernel trick mean mean algorithm formulate term kernel support vector machine perceptron kernel replace kernel kernel prime algorithm model decision boundary work theory work replace kernel algorithm kernel kernel trick replace kernel use instance support vector machine kernel introduce use kernel basis function kernel basis function kernel attend talk support vector machine experiment ask question sir kernel use answer use kernel ask answer kernel trick lesson learned learn lot thank monday habe
welcome tuesday session cancel lecture business trip shift think ruediger tell usage field retina image analysis lot work build screen system check risk heart attack instance look eye analyze vessel calcification vessel retina retina base compute risk index tell risk suffer heart attack instance glaucoma disease thing classifier build screening system classifier use screening system combine use support vector machine classification think expect hope explain decide cancel lecture want want tell use practice example try lift concept language kernel lot thing perceptron algorithm product feature vector perceptron learning algorithm decision boundary instance learning decision stage compute product feature vector idea replace product feature vector transform feature kernel relate transform feature compute product transform feature motivate know feature class feature space decision boundary remember picture circle hope motivate introduce concept kernel feature prime transform mapping product consider product transform feature tell transform apply product define function read feature vector pry prime result value kernel fulfill property kernel rewrite mapping mapping feature follow product idea grow formulation product use let use feature transform feature transform affect algorithm change compute product transform feature step tell system transform compute product kernel mapping decompose circumstance mapping follow product idea future talk phi product talk kernel kernel kernel kernel kernel basis function kernel use norm gaussian basis function kernel kernel mean kernel tell happen happen prime value know theory circumstance kernel compute know exist phi product mapping rewrite term phi mapping feature follow product care look situation care prime lemmata theorem tell function mapping kernel read book theory know know core idea kernel trick kernel trick trick remember term product term kernel algorithm replace kernel kernel write formalism kernel replace kernel kernel statement statement result mind build classifier pattern analysis system lead fact classification base support vector machine architecture feature vector sequence feature vector vary length mean think mean feature vector fix dimension haven speech recognition utterance speak speak feature sequence feature vary length classify know base feature sequence utterance classify learn time warping job winter semester apply classification base feature sequence vary length find kernel function use string kernel learn result start work feature sequence graph structure apply classification theory learn decision boundary support vector machine classifier let look kernel mean know point view know point set feature set compute basis feature set basis eigenvector belong eigenvalue eigenvalue project feature instance coordinate axis know project feature project axis variance space know decrease eigenvalue decrease value compute transform feature transform feature variance remember good let look look rewrite term product apply kernel trick write term product transpose prime write phi transpose phi kernel compute know variant curve project feature curve maximize variant curve thing look literature kernel invent year idea know let kind revolution field field feeling know idea algorithm invent trick look pattern recognition algorithm try rewrite term product kernel trick class algorithm happen know work miracle computation revisit know winter semester know chapter discrimination analysis feature vector feature vector normalize mean mean normalize feature normalize accord follow rule sum number feature case normalization subtract mean vector feature normalize set feature constraint enforce transformation compute mapping compute covariance matrix covariance matrix feature covariance matrix compute likelihood estimate know formula case learn school abitur know case learn version ask teacher question teacher step compute eigenvalue eigenvector decomposition sort know eigenvector decrease order project feature vector eigenvector associate decrease eigenvalue remember sort eigenvector decrease eigenvalue projection projection compute mapping basis transform transform basis algebra know eigenvector spend space feature vector remember case feature vector normalize eigenvector eigenvector direction course spend space base vector coordinate compute point product point let assume coordinate system coincide transpose tell transpose projection point vector coordinate want rewrite point term coordinate coordinate coordinate system compute product mean form basis rewrite eigenvector term combination feature agree mean alpha case course exist combination generate base vector rewrite term combination candidate blood pressure level feel lecture think feature space decomposition observation feature space probability decomposition case space set training datum mean hunt representation use product let write covariance matrix eigenvector eigenvalue eigenvector rewrite covariance matrix term feature vector normalize feature vector mean definition rewrite combination feature vector bring unknown coefficient miracle miracle use know rule summation multiplication reorder thing rewrite eigen equation term component term feature vector replace mean write term product mean following equation fulfil projection index mean mean vector vector vector feature space vector feature space basis project point project point equation fulfil component coordinate system spend eigenvalue eigenvector project thing vector vector fulfil projection span vector feature space confuse confuse project vector feature feature feature mean project feature vector thing projection transform equation project thing feature vector feature vector vector projection multiply left transpose vector projection vector projection vector observation trick bring transpose trick apply typo project feature vector identity remember year product product product apply feature transform transpose phi instance compute product transformation feature step care transform product define kernel function use kernel replace equation kernel sum alpha remember coefficient require build base vector eigenvector feature vector observe kernel kernel sum eigenvector coefficient kernel equation kernel equation kernel invent think researcher germany berlin max planck director tuebingen professor australia guess look mean build kernel matrix element line row column build value build kernel matrix use pair feature build kernel matrix rewrite equation term kernel matrix know remember time introduce kernel matrix component comma compare feature result kernel define component kernel matrix use component writing rewrite thing term matrix pack factor alpha alpha vector rewrite component level term matrix equation sit follow square kernel matrix time alpha time eigenvalue time alpha bring alpha eigenvector alpha eigenvector kernel matrix compute eigenvector kernel matrix proof condition read alpha eigenvector alpha eigenvector factor equation want proof determine eigenvalue read alpha eigenvalue eigenvector problem compute kernel compute kernel matrix observation compute eigenvalue eigenvector kernel matrix coefficient coefficient define eigenvector look alpha combination feature eigenvector transformation like coefficient vector alpha use solve eigenvalue eigenvector problem let look implication kernel kernel generalization compute solve eigenvector eigenvalue problem matrix number feature attend lecture winter semester let way winter semester introduce eigenvalue eigenvector problem reduce computation eigenvalue eigenvector matrix number feature proof tell stuff compute eigenvalue eigenvector decomposition matrix number feature deal image size matter image training compute eigenvalue eigenvector problem matrix result compare compare kernel evaluation compute kernel matrix stuff kernel matrix component compute kernel transformation know care transformation know compute projection transform feature projection transform feature component mean component compute alpha phi transform know kernel transform product know kernel compute projection transform feature vector scalar product product transform feature eigenvector transform eigenvector transform eigenvector sum combination transform feature vector product compute coordinate principle compute coordinate use kernel function let write mean define feature transform know feature feature space project curve variance maximize mean mean innovation assume mind feature vector mean question happen transform feature mean mean apply eigenvalue eigenvector decomposition mean constraint fulfil mean type normalization hope hope write stuff kernel function normalize feature term kernel application feature case worry look let look entry kernel matrix product transform feature transform feature normalize feature normalize transform feature subtract vector vector normalize mean multiply thing end formulation kernel entry kernel entry period rewrite normalize stuff term kernel function evaluation kernel luck need know know define kernel need know minute lecture geht stimmt haven push slow bit let reconsider problem need normalize feature mean mean know achieve transform feature subtract mean mean vector multiply thing product transform feature product transform feature product product care phi product use function use gaussian kernel lagrange kernel use want let look example let look think follow situation image engineering issue mean remember introduce seite einfuegen introduce polynomial classifier know feature feature decision boundary look come transform base equation circle require understanding feature behave decision boundary look idea section cone base intuition generate look datum choice kernel mean datum kind use kernel experiment check know feature behave transform space classifier decide experiment basis tell recipe case use case use case use mean define kernel map stuff idea apply stuff look space curve know margin consider apply feature transform kernel trick apply idea question happen transform feature separate question answer problem problem require lot experiment depend problem way algebra kernel combine kernel thing construct kernel application consider detail core message replace algorithm product feature vector kernel generate type algorithm family algorithm lift idea space let kernel consider kernel look write product transformation compute image compute know learn know eigenvector winter semester compute sigma sum transpose compute variance matrix covariance matrix time time matrix power time power power column row matrix thing start eigenvalue computation eigenvector computation matrix kill system kill system like ask exam byte precision image memory require store matrix learn gigabyte store type matrix want start eigenvalue eigenvector decomposition work kernel trick kernel mean mean compute evaluate kernel pair compute pair kernel matrix combine combine kernel matrix eigenvalue eigenvector decomposition matrix sir image pixel consider feature vector image element matter hold power power power write want check follow fault know mean think explain know example exercise homework problem man problem system know run trick run use kernel replace kernel kernel projection subspace let write compute power run student exam card shame computer science professor compute power tell parent euro tell president let look example let look example string kernel start open eye feeling think speech recognition feature vector feature vector let draw example let look speech word tell word repeat word speak learn winter learn attend lecture winter decompose time axis frame millisecond size window decompose frame speak case frame compute feature vector use cepstrum coefficient know feature vector frame let matter know want compare feature sequence want compare know use sequence compute distance work compute parallel assignment feature belong feature belong feature belong beginning know understand speak feature squeeze frame shooter map speech recognition assign feature frame frame utterance compare thing compute mapping compute mapping signal signal way distance minimize time warping intuition know detail compare component assignment estimate assignment function distance optimization problem involve want implement neighbor classifier speak utterance time compute use technique distance decide word distance want build support vector machine classification want utterance vary length vary length work work find kernel string remember consider vector sequence feature vector find kernel sequence feature sequence mean find implication feature sequence feature sequence replace kernel algorithm learn hide markov model define kernel hide markov model train hide markov model use classification use markov field use classification combination model kernel classifier publish chance seminar winter semester publish session paper combination kernel classifier use use product feature transform idea know fruit hang field guess understand core concept half hour run minute comparison sequence time warping idea express attend winter semester look attend winter semester worry know warping warp signal fit sequence compute distance know mapping tell map index map tell map index time step use combination sequence distance compute programming idea define time warp kernel mean kernel case kernel write power minus beta prime norm prime norm use time warping similarity measure kernel sequence value distance measure kernel function kernel prove kernel proof mean compare kernel build kernel matrix apply kernel feature sequence vary length implement support vector machine margin stuff use kernel mean tell winter semester use speech signal time warping compute similarity measure build classifier decision boundary work understanding thank monday
lecture curriculum computer science mathematic study talk algorithm field pattern analysis algorithm algorithm algorithm start introduce algorithm estimator likelihood estimator reduce transform likelihood estimation maximization scheme function kullback leibler statistic let insert page discuss algorithm stand step direction algorithm algorithm work follow remember variable observable hide know hide markov model hide markov model parameter yes parameter set parameter miss information principle miss information principle information information hide information mean information information information log miss information principle multiply know information theory consider iteration iteration iteration remember multiply iteration multiply iteration consider iteration reason multiply kerstin tell framework problem rid variable marginalization integrate look log likelihood function log log blah function maximize function lead optimization log likelihood function picture mind follow value look parameter estimate let consider parameter illustration purpose let parameter theta yes value theta parameter characterize distribution theta value theta function likelihood estimation tell log log theta log likelihood function maximize estimate theta estimate theta log likelihood function mean log likelihood function look parameter maximize log likelihood estimation function estimate algorithm newton iteration likelihood function follow function compute maximum function theta theta prime maximize compute function compute maximum compute function compute maximum mean maximum maximize function look function function function compute maximum compute function bound function compute maximum disadvantage algorithm work value start function estimate estimate area attraction maximum find maximum situation function log likelihood function start function stick optimum optimum method depend initialization drawback application find initialization function optimize function compute function kullback leibler kullback leibler statistic expectation estimate argmax prime replace hat consider prime variable iterate prime shell brain look read brain time log miss information principle observable focus iteration case prime job integral write integral forget rewrite rewrite accord bayes law divide equation mean bring divide integral compute compute thing know need know density compute probability function design iteration scheme probability density function thing write density thing write joint let look example discuss drawback algorithm let look example pick slide need heart ask pay destroy concept talk kernel example example example need example need example example think example know example mean remember year intend let let think think definition state state generate output think girl door cry word word listen word know girl hide process boy discriminate probability density probability density probability density theta theta density function characterize distribution output characterize girl cry girl cry girl cry wall wall hide state girl listen word know girl charge word listen observe number word variable word number accord distribution hide girl state hide state state hide variable know theta know use know know charge state probability probability shout tell generate probability probability kerstin simone hear know girl allow achim hornegger way talk case listen hornegger compute probability probability kerstin think example idea probability hear word probability time output probability time kerstin time simone probability form parameter density theta theta theta let assume know task stand wall hear word record want estimate probability simone probability kerstin know tell sound magic pattern analysis pattern recognition yes tell home pay buck guy magic entertainment likelihood estimation mean search problem problem example apply algorithm write function let let write problem mention formula tend look iteration write write remember formula integral hide variable variable sum sum integral probability time consider iteration remember divide marginal apply formula replace probability ratio denominator sum letter letter use estimate 'th time problem space continue time log argument logarithm information numerator prefactor numerator prefactor iteration log iteration time fit thing optimize function mean example generate example power algorithm logarithm factor argument logarithm parameter prior mean case know matter parameter distribution state girl logarithm multiplication know operate morphism log log theta optimize function regard parameter care factor separate mean imagine require estimate theta separate parameter parameter logarithm compute gradient disappear computation regard maximize constraint forget constraint probability sum fact constraint sum constraint optimize regard constraint know constrain optimization work case shape prove forget constraint compute function use constraint identity prove situation sit function look cool mean algorithm algorithm mean lambda sum identity constraint maximize iteration iteration write constraint guy write christian mean function parametrize fix scheme fix estimate like bumper sticker hope car optimize compute gradient compute gradient accord probability compute gradient gradient function gradient gradient function compute derivative regard course vector variable argument logarithm argument logarithm component sum survive component consider start theta time iteration divide divide stop typo let theta derivative log regard derivative mail switch time iteration iteration lagrangian lagrangian happen lagrangian derivative lambda lambda vector optimum optimum deal problem mean formula let prefactor look way replace multiply iteration step lambda multiply lambda lambda remember kerstin simone loose lambda identity estimate add hand hand equation add thing sum let iteration index lambda sum iteration sum sum lambda know replace color want green green sum mean mean write close form estimation rule write equal point finger time probability look sum divide sum divide sum divide sum replace definition ratio look formula mean estimate probability simone observe word source estimate probability mean knowledge assume theta know probability assume know course induce knowledge system compute probability know know source wall hide source generate generate word steer prior think coin mean academia think coin coin distribution accord girl know girl know decide guy request word throw coin decide base coin word throw coin probability lady word throw coin look coin girl word observation observation end day estimate probability girl number girl number girl number request time word accord distribution girl cube girl coin mean mean girl word throw coin signify probability source number source number source number generate word prior word prior observation mean prior open york time ask probability word obama probability agree open york time probability hornegger schwarzenegger sound hornegger mean hell york time know open envelope york time probability write professor mean care word compute probability girl use algorithm structure underlie hide variable rid variable integration use structure apply apply algorithm mention estimate parameter search search subspace estimation situation search search know mean search space coordinate start search instance discretize axis visit point look function look direction direction direction beat curse dimensionality break thing search problem happen close form iterator implement line matlab code mean break line matlab code code situation variable variable integrate marginalization use apply algorithm method discuss hide markov model hide markov model kind outlook transition probability girl probability girl word girl word hide markov model minute leave thing lecture think tell stuff learn algorithm function maximization constrain optimization circumstance example formula grow grow grow stay mechanism probability density function apply algorithm experience identify situation future parameter variable hide variable instance mixture example discuss mean probability parameter step hide variable parameter need experience thing think time stop thank monday subpart lecture
welcome monday session discussion expectation maximization algorithm hook avoid draw picture information compare monday talk expectation maximization algorithm question expectation maximization algorithm work need identify identify component estimation problem candidate stefan component identify estimation problem observable hide parameter estimate parameter algorithm maximize function accord parameter function stefan time course rewrite term probability trust need marginalize week deal mixture mixture mixture density mixture density observation carry feature sum mixture component write vector parameter probability mean sum idea sum density function density function compute combination density function think following feature feature feature gaussian gaussian characterize compute time gaussian vector sigma sigma characterize density thing case instance generate combination density function know structure maximum density function fulfill criterion probability density function integral mean area axis function suppose case case let let proof sum combination combination combination sum sum allow build gaussian instance shape density function technique gaussian lot combination gaussian model probability density function use pattern recognition application course proof function density function approximate combination gaussian limitation remember application bayesian classifier model maximum use combination gaussian job stefan fulfill constraint let write detail note end linearity property sum integral sum integral position fact lead sum coefficient combination sum fulfil constraint know build know shape description description density function look find know parameter characterize combination use combination gaussian base hide parameter estimate tuesday variable find estimate prefactor prefactor mean remember detail prefactor coefficient combination ratio computation ratio computation let look example let continue example follow probability density sum computation fly slide die know detail write step step assume following assume histogram let assume let assume sum assume probability write way let assume mixture component remember time state generate output state consider probability look write sum characterize frequency let assume vector probability instance think generator generate number number accord density accord frequency integral sum mixture density build prefactor tell probability state action frequency map example week girl girl tell number know generate number wall need estimate probability probability probability know estimate week output probability frequency state estimate mixture variable follow stop thing year estimate instance suggestion stefan write function write function estimate function prime integral sum state case consider case need prefactor ratio parameter time divide sum let sum logarithm information prime consider iteration step time prime sum ratio log prime log prime squeeze optimize regard compute derivative compute derivative regard variable variable number prime derivative stefan shape logarithm spit parameter set forget log prime derivative end prime way look prime consider variable bit way need lagrange multiplier talk hold integrate sum ask sum value histogram sum sum space way write lagrange multiplier way tuesday let copy let try einfuegen let know know stop let sum need equate listen time parameter want estimate lambda sum stefan select problem formula fix oversee compute derivative oversee sum select sum disappear element sum share look disappear cancel pardon sum got compute derivative regard cancel argument tuesday let let write let rewrite fix lagrange multiplier consider derivative compute derivative regard derivative derivative regard kerstin lambda lambda apply trick lambda lambda multiply lambda prime slide run issue rewrite bit trick stress bit prime happen sum happen stefan constraint lambda sum bring equation star star time prime sum prime prime iteration scheme jochen formula estimate probability frequency select fix state estimate estimate prefactor output probability use formula sum prefactor mixture density output probability learn formula need learn formula remember year remember algorithm derive look formula prepare exercise problem output probability state probability frequency use gaussian derive formula estimate mean covariance matrix mixture component implement scheme implement shot implementation want run mixture work require core idea discuss summarize summarize know mixture know mixture sum know mixture definition mixture know estimate parameter mixture use algorithm compute instance compute probability observe feature set observe instance feature vector point image instance vertex cube corner corner compute add parameter component vector model mixture density distribution write density function write product let assume observation instance think pattern analysis problem want recognize object know object model corner write corner term set vector characterize corner want know probability observe corner mixture density know corner observation belong write probability density function sum state complexity evaluate density function complexity product component sum element let look probability density function point view write let wait second probability observe use basis mixture density model assumption observation let look undo let look let look point view let come example image corner corner corner observe let assume know state corner generate image point compute addition know state charge corner corner number corner number corner number instance model state state state state generate corner image generate feature generate feature generate feature probability know feature generate state information mean product stefan write product state time explain run observe point index state charge observe feature probability state generate output probability generate output consider want compute compute state combination state probability describe question density comma parameter know state know state probability remember girl time example know girl utterance know girl generate output assume output write density function observation product agree probability know girl generate probability girl generate observe compute density function know girl compute look mean probability evaluate complexity evaluate mean factor complexity evaluate sum possibility power complexity power time evaluate compare density reorganizing operation explain core message mean compute use mixture model observation generate state girl multiply come complexity let assume know state sequence probability marginalize end probability density function power time complexity reorganization operation end method introduce slide destroy writing look look need hide markov model motivate lot capital semicolon sum sum observation state argument write know state generate feature know state generate feature probability product multiply feature probability state generate output time sum want compute sum feature state girl generate feature know girl sum value eliminate state generate output marginalization feel use notation sum sum know type writing combine sum let motivate girl example think way observe product state component state state state generate output time probability yes state number number time output probability state time time time tell state generate state state state state state tell state know state know state marginalize state combination marginalize state combination probability observe know state charge marginalize think example got write manner admit sum state follow reorganize bring complexity idea understand compute ask reduce complexity mean look sum product component product depend product component product bring prefactor sum rewrite sum time time sum time bring summation variable apply trick component bring prefactor end follow sum time time sum time sum time product sum summation variable let summation variable mean rename product sum sum complexity come compute complexity evaluate probability density function reorganize operation sir feature thank pointer consider feature formula apply mixture mixture model derive formula compute mind understand moment hide markov model square complexity hide markov model evaluate proof tomorrow audience idea mixture compute density involve mixture way ask exam write estimator compute coefficient mixture density mixture play role pattern analysis pattern recognition mixture play role play role pattern recognition patter analysis example state art speech recognition progress people start deal model pattern recognition application talk concept like delete interpolation talk delete interpolation power algorithm power mixture provider problem pattern analysis think following build word model language model build language model mean day speech recognition people start write grammar know language try characterize language use language use grammar know grammar computer science people know people build grammar look language notice sentence generate grammar generate rule grammar look millisecond find example cover grammar people sit work grammar pattern recognition people build grammar kind work lead solution let people search grammar think idea build grammar build model language newspaper web book web generate probability probability word chain instance generate probability table probability word follow word word word word gram speech recognition technology compute gram probability compute word combination kind probability lead knowledge use classification purpose know talk lot classifier kind knowledge observation probability sequence word think follow think let gram assume language consider consider word vocabulary consider language vocabulary word tell parameter compute characterize probability density number degree freedom number degree freedom time power probability estimate power probability word combination think number number access web text generate world instance german language time estimate power probability probability mean observe combination mean want estimate frequency need way power example estimate probability people pattern analysis pattern recognition run problem idea build language model end day turn datum generate language model end histogram instance look case look instance word word word word word word observation probability histogram hole order order order dependency gram histogram gap entry compute probability entry system break multiply prior people bias epsilon probability value epsilon work example come estimate gram idea interpolate interpolate histogram follow gram example let look gram sir interpolation know algebra numeric algebra listen minute come question idea interpolation follow people want estimate sir interpolation think term geometry forget want point histogram gap hole fill strategy language model word power entry histogram people following dimension reduce degree freedom consider time bit combination gram word follow word word follow word start word probability function replace combination order dependency sir mixture mixture model order joint density function mixture order joint density function delete interpolation people extend bit omega omega end estimate omega omega omega omega estimate frequency use text datum basis estimate parameter estimate parameter mean year idea idea model order order histogram mixture order histogram delete interpolation estimate estimate estimate mixture formula estimate parameter prefactor mixture divide sum mean formula care omega care think term object orient programming probability density evaluation method implement estimation level probability estimate coefficient mixture density formula derive tuesday delete interpolation use method introduce use algorithm estimate search web google delete interpolation find speech analysis system deutsche museum use delete interpolation build model compute mean idea compute know compute formula contradict work sum combination combination combination compute use algorithm end iteration scheme delete interpolation equip algorithm open eye look following try find paper delete interpolation web look compute parameter paper construct kind hide markov model structure map hide markov model learning rule delete interpolation problem paper people use formula derive write use algorithm derive parameter write estimator audience know compute use hide variable variable parameter estimate compute function compute derivative care fact sum use lagrange multiplier method compute lagrange multiplier end iteration scheme know scratch remember know estimation formula hide markov model people world clue estimate derive estimation formula hide markov model parameter look tomorrow derive estimation formula use algorithm admit need context formalism feel computation appear question motivate hide markov model tomorrow consider detail learning formula computation marginal path talk hide markov model talk hide markov model hide markov model mixture state let consider hide markov model state hear hide markov model markov model coding hear estimation formula state probability state state generate number output draw mixture probability probability probability observe measurement compute probability state number state number state number state number hide markov people observe probability argument want dependency want dependency hear number number sequence want probability observe measure independence want introduce dependency dependency order markov people probability remain state ask output remain state remain state probability probability probability probability probability probability probability observe know visit state compute probability story case mixture probability observe follow path probability stefan probability produce output sequence write observation state stefan yes probability start time product observation product gay write start transition probability state end product run probability sequence generate hide markov model homework problem compute sum complexity power proof tomorrow sit think find generate viterbi algorithm evaluate marginal algorithm apologize technique mean state art speech recognition speech analysis system use fact impact thank tomorrow
tuesday session teach english speaker list want finalize algorithm like talk hide markov model look training formula hide markov model type hide markov model address question discuss context hide markov model know algorithm algorithm work algorithm scheme emulate likelihood estimation core idea likelihood function maximize function end maximum initialization guess area attraction maximum area attraction attraction area attraction set point gradient point maximum know company brain lab brain lab deal brain visit july want join travel munich listen company presentation want attend know want algorithm algorithm need characterize function function expect expectation function maximize maximize function define remember formula algorithm deal miss information principle mean information information information hide information know stuff core function multiply integrate hide variable function maximize function know function logarithm logarithm split product probability sum probability property lead fact optimization problem decompose space optimization problem fact logarithm break product sum compute gradient variable variable derive function vanish disappear core algorithm know algorithm method learn system matter mean speech recognizer want train use training sample night parameter adapt night run use system classification algorithm time stuff discuss hide markov model discuss hide markov model state input probability transition probability process combine automaton process probability use start thing probability start transition probability output probability output people combination process introduce state start probability start produce output matter start probability state use hide markov model let copy copy know let introduce page let look example transition probability wall girl example wall automaton outside wall brick wall brick wall hide fact dependency order lead markov dependency model model speech generation process hide markov model abbreviation speech recognition people pattern recognition people compute feature apply use use training pattern recognition know mean work mean process variable generate state generate accord density function density function density function generate output sequence follow knock wall symbol throw coin probability start let assume start time token knock door need measure need feature vector state generate vector feature accord density function probability knock wall guy need symbol guy sit token sit throw coin probability remain probability let assume probability token knock door need feature vector generate feature vector accord density generate feature vector let continue need feature need feature hide markov model need feature token throw coin remain let remain knock state generate variable vector generate continue generate feature sequence length drive process probability tell probability generate know feature sequence instance know associate state sequence generate probability state visit measure state let sum consider state sequence assume generate state sequence marginal introduce feeling leave lecture understand marginal compute hide markov model state sequence generate feature sequence consider evaluate detail discuss question let assume follow define architecture topology hide markov model instance want hide markov model probability markov model density gaussian let gaussian feature gaussian knock door knock door need measure generate accord gaussians hide markov model use model hide markov model use compute probability feature sequence ask write want join brain lab write forget matthias kerstin kerstin kerstin kerstin stefan time feature sequence know lecture lecture training set feature instance speech signal end decompose winter semester suppose winter semester decompose frame frame compute feature vector know shooter speech signal story feature sequence comment state visit state generate feature sequence feature problem learn estimate estimate mean variance gaussian use observation hide markov model use algorithm year forget hide markov model know state sequence way state know process process hide hide variable hide variable know algorithm use algorithm expert browse web google learning training formula find baum welch formula baum welch formula implement training algorithm sustain knowledge browse thing let think derive equation derive equation problem core problem estimate mean covariance mean covariance estimate thing suggest matthias listen state got got problem structure learning topology hide markov model problem solution people define set state training run experiment add state increase estimator tell number state variable select engineering point like solution experience number number heuristic select number topology use problem use speech recognition speech recognition hide markov model switch state remain state state know speech signal time order error error edge hide markov model use speech recognition markov model model stay state model markov model link state self reference model graph hide markov model use use type markov model literature distinguish type hide markov model hide markov model hide markov model rely output probability state probability talk hide markov model density function gaussian hide markov model hide markov model markov model graph output probability probability density function measure variable consider hide markov model remain state output probability frequency question number state fix question matthias estimate parameter estimate parameter problem discuss use algorithm invent year invent dempster liard rubin information care want apply algorithm identify thing parameter parameter simone kid kid know measurement feature let let feature feature sequence let consider feature sequence lift feature sequence state indicie state state number element state feature know state generate state state admit parameter forget guy parameter stefan hide markov model theory write vector write matrix probability parameter output density literature interrupt lecture point look finish interrupt write index state state literature lambda lambda read paper hide markov model theory write lambda triple input probability transition probability parameter characterize output probability point rest engineering rest engineering rotate wheel engineering record finish rest engineering kid plug thing let compute prime jochen boost blood pressure bit increase heart rate variability lecture prime need paper sum hide look identify observation feature state thank purpose check let write way mean feature sequence know state know feature sequence state sequence term start emit feature emit feature direction product matthias observation transition product agree guess let clean thing divide marginalize prime prime prime state copy index prime product product prime write definition function identify engineering time algebra arithmetic time matthias logarithm prime iteration step sum log sum log prime need bracket break logarithm parameter need estimate iteration step prime prime prime prime separate term sum transition probability output probability optimize compute regard instance term disappear optimization problem deal subspace search subspace observe optimization problem decompose subspace optimization markov model search space subspace sir difference sum sum change mean integral divide integrate factor element sum nominator factor logarithm depend
let continue text monday morning discuss mind map tell feel repeat mind map evaluation student appreciate mind map let investment minute picture tell browse video prepare lecture focus mind map feeling think work topic prepare mind map heart heart write thing way generate question exam think topic generate question fly prepare question exam generate fly know write read web know read discussion exam question come guy write mean discuss want guy ask tell truth ask focus topic lecture exam lecture focus winter summer semester winter semester introduce core concept classifier signal acquisition filtering feature classification summer semester view thing focus modeling probability think pattern analysis teach summer semester mind cloud cloud class number feature vector change notation decision notation simplify derivation think support vector machine think think rosenblatt perceptron use variable number write thing compare notation use winter semester decide adapt standard respect notation feature vector class number dehydration problem people apply research project want detect dehydration people use sensor know problem dehydrate drink measure skin measure know activity toilet instance check people air fluid thank pointer discuss probability course question probability stefan stefan stefan stefan think know look heart heart probability probability fill evaluation form mistake think vote quality tutorial want classify want classify probability look maximum want minimize cost loss decision cost function thing choose decision rule decision rule decision rule time decision rule formula know abitur maximize know optimality proof optimality summer semester proof introduction loss function try model probability type factorization probability density function decide candidate candidate day year stefan think stay class density model model kerstin talk gaussian mean pardon use gaussian talk mister color color like estimate decision boundary use regression regression classification problem feature feature decision boundary build probability lead type decision boundary characterize power use sigmoid function regression type optimization problem run deal regression pardon decision boundary affine function solve optimization problem term likelihood estimate consider model class density instance use gaussian idea gaussian gaussian know gaussian look know bell curve look decision boundary end use gaussian class decision boundary look question choose gaussian choose polynomial degree estimate decision boundary mean know gaussian end function parameter estimate question parametrization ask exam parameter estimate gaussian gaussian parameter estimate use mixture gaussian instance look characterize class characterize class mixture mixture plug decision rule decision mixture learn adapt set training sample use algorithm instance feature set use feature vector feature sequence generate characterize class density build hide markov model classify feature know instance hide markov model discuss discuss stefan ask candidate way fill evaluation form day decide vote work grade thank vote quality tutorial correct thank discuss talk rosenblatt perceptron idea rosenblatt perceptron function want minimize distance misclassifie feature decision boundary time mixture parameter parameter optimization procedure introduce gradient descent method algorithm converge remember time lecture bit learning theory tell convergence learning learning method thing invent way week interview guy apply trainee position lab know bilden fachinformatiker guy guy course read know certificate invite guy grade math history course history happen guy know teacher ask question want year want write explanation trouble question let ask question know guy sit wake ask question ask world war end end world war understand question want know year world war finish smile tell technician bear world war war people time think issue life guy religion tell happen situation talk talk stefan stop start talk thing know pay buck information topic idea solution boundary yes explain draw draw draw draw draw draw maximize margin know support vector know come chapter optimization theory optimization lot introduce kernel algorithm product replace product kernel function kernel rosenblatt perceptron kernel introduce kernel invent year discuss feeling know time derive idea kernel use application sir method use boundary decision stuff kernel function decision mean kernel lift idea consideration result gain lift decision boundary case practice people focus design kernel situation think mention time listen use use basis function kernel kernel try decide kernel people play turn theory tell set training datum kernel know mean people research field know algorithm tell kernel decision problem try use kernel kernel time warping lift idea feature vector feature sequence vary length observation talk talk bit optimization optimization talk norm math mean lecture mathematic attend experience people equip technique require student know lagrange multiplier know bit know duality gap thing lot mean guy lot information question forget forget stuff question remark stop time stop time talk algorithm hide markov model remember guy come question remember guy know mean difference numerator denominator stop recording multiplication mean numerator cancel thing appear look line product element sum revolution mean throw phone speech recognition device use training training strategy tell company buy mercedes speech recognition system phone tell story guy read know manual manual system adjust train guy time training adjustment system trainee look manual training guy sit guy train speech recognition system mean estimation input probability transition probability output probability guy ride car trainee system work guy complain lot system work support training guy know hour discussion turn training know let adjust user question happen car trainee repeat word require build training datum set want estimate input probability half hour preparation guy input probability type slide chapter way criticism image processing change slide know want save printing cost want set thing lecture transition probability transition probability friend parameter output generate output want optimize respect parameter jochen try maximize maximize prime constraint input probability sum constraint transition probability sum sum self start think state want sum probability touch wall complain wall mistake mean constrain optimization problem solve mean look mean logarithm job term separate know parameter type parameter deal compute gradient compute repeat sentence compute gradient stage dementia appreciate series comment compute time gradient happen mean sum gradient let look happen prefactor let prefactor color pink weekend let look soul maximize build prime lambda sum tell lagrangian constraint incorporate end turn solution function fulfill constraint need consider term setup lagrangian write need formalize inequality constraint maximize question stefan mention lagrangian way prime optimize respect prime mean cancel forget incorporate focus maximize compute gradient respect prime lambda sum prime mean vanish look sum number state run number feature number state time time stefan steven logarithm logarithm lambda gradient respect gradient kerstin formula logarithm fault state state question comment shooter time mixture delete interpolation stuff sum logarithm probability constraint mean write estimator estimator look jochen recognize recognizes recognize watch video situation sum log lambda sum solve time time time estimator divide sum deal index index sum numerator fix denominator compute mean feel feel want prove follow sum pardon sum set change sum accept change write detail let let start page estimator glaube trenn mich lila hat hat estimator sum sum latex hand write divide ratio ratio sum want destroy lecture remember want destroy homework check read sum concept search web look training formula hide markov model mean book publication reference formula people know derive formula know let look transition probability transition probability want estimate function look constrain optimization problem question function look include multiplier prime lambda sum way start yes tell index index consider state consider state write sum discussion help state sum write state state state feature thank time logarithm logarithm product transition probability logarithm way logarithm come come equation algorithm consider information logarithm sum run start line connect start line connect mean sum start function definition function lecture sit write function optimize function term prime focus look hold second index equality dementia start start know write check video happen run forgot matthias transition transition index feature minus feature number interval number interval state characterize state number characterize state number characterize state number sum consider feature vector associate state bit know bit maintain overview prime optimize prime maximize lagrangian matthias fix estimator fix derive compute gradient regard choice index run sum let fix compute derivative know number time logarithm lambda constraint probability ratio prefactor translate ratio sum sum divide index look mean sit think ask exam mean want computation mean force decide happen sum logarithm gradient sum skip numerator sum maintain denominator output probability output probability probability formula output probability gaussian formula mean vector covariance matrix thing implement year system use speech recognition look web hide markov model toolkit hide markov model toolkit use people work hide markov model pattern recognition pattern analysis write hide markov model system people use hide markov model toolkit develop group cambridge england great britain market buy domain version source source markov toolkit use speech recognition bioinformatic genome sequence want apply hide markov model start experiment use domain software lab toolkit develop year isadora system isadora algorithm method hide markov model implement find training formula estimator introduce implement notice work run problem number precision system scaling trick require work detail scaling require note implement test work blame guy explain lecture work situation run problem number precision reason multiply lot number range probability transition probability input probability product factor range value imagine thing deal type problem scaling result question context hide markov model question question matthias ask select number state problem select number state use heuristics problem start state state state look work problem audience solve day solution question train learn parameter question answer use algorithm read literature find guy welch derive learning formula input probability transition probability output probability baum welch formula proof proof baum welch formula like understand know read know algorithm forget baum welch derivation use function identify hide variable variable constrain optimization save derive formula equip algorithm learn summer semester lecture question question classification use hide markov model want know state sequence state sequence observation want compute state sequence maximize feature state markov model want compute state sequence state sequence observation hide markov model compute state sequence generate sequence output yes compute viterbi algorithm learn algorithm follow dare ask question winter semester viterbi viterbi teach pattern recognition pattern recognition viterbi formula transition probability detail detail require compute denominator state sequence state compute mean compute compute compute compute mixture model complexity remember use algorithm solution algorithm complexity square complexity viterbi algorithm square power choice choice complexity reason apply programming hear programming audience hear programming candidate learn programming signal processing speech audio learn bellman optimality criterion fulfil mean hear solution path solution right bellman optimality principle apply programming core question mention context hide markov model problem learn state sequence viterbi algorithm explain discuss viterbi algorithm time minute want tell thing year extend hide markov model win paper award conference year start understand algorithm hide markov model rid baum welch theory derive estimator thing manner manner idea want speech modeling language modeling language modeling consider precede word predecessor history start think start think hide markov model history consider transition probability state state introduce generalize hide markov model consider transition probability state state consider instance probability state hide markov model yes course transition transition idea look transition mean probability look consider state probability consider probability consider history probability fact build learning scheme generalize viterbi algorithm algorithm turn history history complexity square history case think thing generalize application language modeling use generalize hide markov model equip math know math compute learning rule estimator identify write function write constrain optimization problem compute derivative require vanish mean mean formula grow grow look implement use use year appreciate community define topology want know constraint consider automator structure instance build output probability mixture estimation mixture assignment mixture component estimate parameter markov model state output feature vector feature sequence estimation parameter model mixture mixture mixture mixture share covariance markov model hide markov model hide markov model read literature equip technology allow understand relate hide markov model thing week
welcome monday session week semester terminate topic discuss love think level stuff end pattern recognition pattern analysis learn rest week program mind map discuss question question hide markov model bit explain algorithm use want implement thing like bit theory markov field use modeling principle image processing let start mind map think page mind map think winter summer semester summer semester focus area pattern recognition look way characterize probability probability know core bayes classifier bayes classifier use decision rule decide class probability discuss way model posterior use feature sequence feature set use feature vector dimension fix dimension change signal use classification course demand constraint define constraint record record speech people know pronunciation emphasis stretch word mean associate fix feature vector utterance decompose signal frame sequence feature use theory object classification look object vary illumination run corner detector image mean position orientation light source find vertex corner image number corner vary use corner classification work feature vector set use edge vary illumination constraint fix dimension look theory pattern recognition pattern analysis find result basis classification problem fix dimension feature vector consider context dimension feature vector fix model use regression model time datum datum class density function approach deal instance use instance model decision boundary decision boundary base deutsche bahn decision boundary stand decision boundary decision boundary context classifier decision boundary gaussian share covariance parameter tying parameter tying tie covariance time prepare exam think happen tie gaussian happen matrix tie matrix thing behave play toolkit provide exercise discuss feature vector break thing product feature component assume component case factorize way instance generate feature vector remember transform feature end end distribute feature vector sound miracle experiment exercise project feature vector generate component interval project observe look gaussian component design feature apply end day bayes classifier bayes wording idiot classifier idiot way justify assumption distribution feature apply testing instance assume variable distribute use kolmogoroff smirnoff test testing check distribution assumption testing way justify choice density look construction feature vector construction routine know type distribution occur instance know theory component way density assumption mathematician engineer choice system work culture start distribution try want build classifier start distribution mean classifier training set classification rate point percent mean bother change thing work argument argument mean think case prove level feature follow distribution implement work know circumstance environment lead problem consider model work help build signature reader reader signature recognition system misclassifie signature bank manager tell bullshit explain look justify distribution care end day thing work accord computation bridge accord observation bridge intuition mean base theory end day design experiment build thing learn feature transform classify set datum require minimize maximize raleigh coefficient set optimization situation want model feature distribution feature gaussian feature distribution use mixture model model mixture model mixture model mixture model describe decompose probability function number mixture component class course component probability sum mixture instance gaussian use combination gaussian combination gaussian combination gaussian prefactor fulfill constraint sum combination use instance model shape know learn parameter mixture estimate observation know exist method deal information mean tell work know mixture component charge observation context algorithm remember density parameter estimation technique learn likelihood estimation estimation algorithm equip method survive field pattern recognition use information method estimate parameter information maximize discuss equip method read paper equip method read publication field deal parameter estimation mixture model feature set feature set observation feature set component feature set use feature set classification decide class maximize difference vector color let try yellow interest set feature model density set feature time capital mixture instance think object thing corner corner object model gaussian feature come know corner miss assignment function mixture observe corner know date mixture charge corner use mixture point extend feature set component assume classification problem feature sequence length sequence model hide markov model journey follow feature vector transformation feature vector introduce mixture model provide feature vector use mixture model feature set feature set use feature sequence dependency order feature feature sequence story talk perceptron talk support vector machine talk norm talk optimization technique way look story feature vector feature feature vector mixture model mixture model feature set feature set feature sequence look feature sequence lattice feature graph neighborhood relationship use neighborhood relationship introduce dependency explain want emphasize prepare exam study overview discussion discuss aspect know thing know think feeling develop question exam question comment lot know question comment tell question question relate hide markov model jochen question mean answer think state think state state topology assume model model graph transition probability epsilon yes topology determine number learn observation train parameter observation need method compute state sequence grade compute state sequence observation state generate feature require work level speech recognition want know instance word fall category use language model need labeling assignment feature vector hide markov model completeness motivation remember mixture set feature vector compute marginalize state state mix feature remember use mixture model model density function state use product time bum write write index write index prefactor weight probability state probability date write index consider feature feature sequence consider parameter state end product sum sum product computation rewind video position complexity power time complexity reorder operation run run hide markov model state sequence compute square introduce dependency order feature complexity mixture hide markov model increase increase factor achieve complexity follow run consider marginal hide markov model reordering complexity break complexity look boost metabolism body tell marginal hide markov model state sequence blood pressure ramping ear order mean case sum hide markov model sequence feature feature order bracket hide markov model hide markov model lambda remember lambda triple input probability transition probability output probability sequence associate state sequence markov model sum state sequence number state write sum sum obama write start state folk ask exam write density state sequence feature percent student emit feature use emission density state emit feature end emit state write form time end product output run pardon think multiplication number property reorder thing time time insight mean explain beginning start talk mean formula look notation know math grade mind guy mean encourage lot guy mean multiplication check complexity evaluate jochen time mean computer scientist know compute judge complexity derive complexity power time sum sum state possibility state possibility state possibility power product component let scaling factor thing end time reaction mean want implement want compute run complexity phone speech recognition system feeling time bring thing complexity time situation mixture model mixture model assume feature vector hide markov model scheme transition state assign feature sequence order order predecessor decide success think history complexity change thing power complexity derive formula dependency exponent dependency order exponent order dependency exponent order depend predecessor use generalize hide markov model order order exponent increase term complexity reorder thing complexity let copy want copy lose hope find time type thing web laugh record shame ask situation people problem tell professor computer science know professor computer science know hat mean notice time saving think write thing bring complexity remember time deal mixture reorganize use result math use result math let use follow lemma proof use reorder thing use result equip result prove complexity power square mean try sum sum let sum copy touch write accord rule rule mix bring component product yes leave time write bracket element let try advantage compare notebook state element sum jochen agree component component sum drop drop factorize case mixture transition probability yes know element glue thing look end complexity power time literature read literature algorithm derive way describe way remember thing rule know know formula reorder thing derive algorithm need structure algorithm use literature people introduce know notation parameter end day prove result algorithm way want remember thing future mean square game idea let write know step type notation input probability sum copy compute compute value sum evaluate fix fix state number evaluate sum evaluate sum state fix state evaluate sum time evaluate sum time evaluate sum time result compute result fix fix compute compute sum component vary state time element result sum state compute compute sum fix state state compute time compute time compute time time time think evaluate bracket compute time power algorithm implement wollte cancel loeschen algorithm complexity introduce shortcut introduce shortcut probability let look algorithm describe literature pick idea develop look evaluation algorithm algorithm look follow sequence element time step feature end state hide markov model lambda alpha variable mean probability observe state fix state fix state lambda sum lambda sum alpha agree understand agree focus exam mean state state want end probability want end probability state state time step use probability compute look control theory know initialize alpha alpha kerstin kristin mix time kerstin know bit blood signal alpha alpha alpha alpha mean mean probability feature state time emit induction step number state compute know reordering element product sum come game pardon write think answer question purpose question come want write probability stefan identify address way got game switch know self system learn use catch use look write fix thank irony agree agree mean state time step emit sir sum beginning index trick irgendwo drauf klicken bitte break system stefan let live thing terminate thing markov model sum alpha variable sum wing time step let look complexity compute product kerstin state element compute compute sum element time square square element feature sequence time square end day summation complexity square formula reorder summation way slide drop summation left right pull summation summation decompose beginning algorithm algorithm algorithm complexity square bound multiplication element sum element compute sum element time square time feature complexity compute state sequence replace summation maximization end end day viterbi algorithm let like start hide markov markov field state sequence use viterbi viterbi man person patent time live san diego enjoy life pointer learn company mean underestimate thing company patent know company people guy guy patent company decide buy patent mean care people buy patent patent industry patent want build product use idea pay patent use idea buy company thing mean patent apply patent lab apply patent year lot patent work allow use loop pay algorithm patent europe software patent problem game viterbi algorithm compute state sequence proceed set optimization problem kerstin consequence course evaluation candidate notice optimization problem want compute state sequence star business star star feature feature sequence element star state sequence maximize probability observe probability observe feature argmax feature sequence state sequence way classifier state sequence markov model maximize observation observation sum replace hand write max operator mean compute sum state sequence compute maximum state sequence use algorithm describe slide replace sum max replace sum max square algorithm compute state sequence conclusion replace sum algorithm algorithm max argmax operator end viterbi algorithm complexity square mean compute state sequence complexity mean search combination search combination look algorithm end programming pattern recognition learn method programming programming algorithm theory hide markov model know training algorithm know algorithm reorder operation know viterbi algorithm use algorithm replace sum maximum operate question regard point time hide markov model state art speech recognition use speech recognition device car phone hide markov model implement bar meet girl want explain girl know guy know explain girl boy phone work speech recognition typo compile morning latex morning command backslash remark pencil mean sequence feature sequence feature assume extent consider feature depend predecessor look image image grid intensity value depend neighboring dependency value want characterize distribution intensity value need neighborhood instance characterize assume pixel assumption neighbor pixel intensity corn question set model allow hide markov model thing markov field thing describe grid remark mean field lattice variable generate know matrix structure variable field introduce image processing researcher abend time time happen paper know publish annal statistic reference reference paper image processing community publish geman geman researcher share introduce markov search web paper find thousand paper use paper basis research leap research field introduction markov field read paper read core idea basis modeling scheme use image processing mean purpose introduce markov field advantage classifier relationship model classification theory need repeat omega kappa replace want classify maximize probability beginning todays lecture estimation parameter work variable value variable maximize combination logarithm regression classification regression consider output classification consider output thing let consider image lattice lattice gitter lattice lattice intensity value grid look matrix characterize image consider matrix consider matrix compute probability observe matrix consider image let bit quantization intensity value probability space value pixel power probability space sense know look image think cover probability density function marriage picture marry include probability include picture marry include intuition space work mean find smile marriage picture include year time study joke year space think space want come model characterize image mean job imagine imagine lattice point pixel picture index variable associate point variable denote instance intensity value color value segmentation result value edge edge probability observe image image matrix question model think mean year conference december conference pattern recognition guy award work model image deal structure insight image processing theory classification theory term image processing image analysis model let think like characterize image probability density function fashion fashion probability observe matrix intensity value deal idiot let assume pixel let let assume pixel product compute remove compute probability intensity multiply thing instance compute probability press button image compute histogram probability intensity probability intensity build density probability image problem mean pixel work run problem image probability probability end value interval multiply number luck computer end result number work apply logarithm try scaling thing thing multiply number multiply multiply probability image marriage know point view point view extreme assume dependency idiot approach bayes approach question instance choose color value depend instance neighborhood probability value value consider neighborhood introduce dependency dependency order order instance depend neighbor value depend neighborhood neighborhood build model learn tomorrow learn tomorrow summarize thing characterize density function form use function prove hammersley clifford theorem dependency order rewrite probability density function use gibbs allow model image structure use pattern analysis modeling scheme markov like discuss tomorrow thank monday
tuesday minute session semester level pattern analysis pattern recognition semester stuff lecture student lecture semester want try introduce markov field theory point theory impact let killer application know system use markov field money concept use research project lab use markov field instance segmentation spine segmentation lung thing project use markov field idea motivate hide markov model state transition orient graph consider graph orient edge vertex define dependency structure want pixel image depend pixel image draw vertex draw edge vertex neighborhood structure repeat image pixel neighborhood structure point mean ray reason define neighborhood reason define neighborhood image mean space space image probability measure space example image image marry marriage photo include set tell event probability point happen event probability need reduce space bit idiot approach mention approach assume pixel density break situation use baye remember justify baye construct feature instance know gaussian bayes sense image type independency sense image noise pixel noise sense image acquire camera device dependency dependency question answer look neighborhood instance order markov mash field way look probability probability pixel pixel reduce probability neighborhood structure illustrate matrix structure write thing comma comma close bracket matrix indicate neighborhood relationship write pattern recognition fashion express neighborhood relationship use problem boundary treat boundary example point value neighborhood value imagine value estimate number value histogram think let case let look bit quantization bit quantization mean bit represent pixel value mean pixel value pixel value probability estimate entry entry entry entry mean power pixel estimate configuration estimate value imagine thing explode bit quantization camera neighborhood thing space want compute probability observe image mean compute product image pixel image use density express formula neighborhood decide probability observe density point computation use use probability theory learn year undergraduate level course mean value depend depend neighborhood effect want compute density consider neighbor use modeling apply type idea image image capture image mean noise image measure system measure image observe image image transform observe image pixel value value apply classification theory filter image maximize probability max segmentation method want want estimate want estimate value image use observe intensity image situation pattern recognition feature vector intensity value observe image class number intensity value image base observation want estimate image thing bracket indicate consider image compute image maximizing image filter guy write hand writing problem bayes filter problem problem question build classifier know mean simplification introduce introduce simplification instance intensity depend mean neighborhood dependency situation pixel value depend yes distance mean cover consider density constraint intensity observation assumption assumption reduce dimension problem reduce dimension problem deal curse dimensionality remember curse winter semester know curse dimensionality tell space behave constrain feature space acquire sample data set training training sample border space feature border sample space generate training sample term problem distance feature hope elli explain bit space cause problem cause problem thing behave expect thing behave paper read paper people know testing check dimension vector term classification result run experiment feature vector perform try find argument feature vector perform explain know noise come curse curse end day space classification cause problem curse dimensionality issue assume variable reduce dimension search space idealization fit world reduce dimension problem way issue curse dimensionality assume model degree dependency mean map thing model parameter degree freedom lead curse dimensionality system break example break curse dimensionality idea come system stop pain august erlangen area lecture office curse dimensionality think following variable let look let look example variable value measure generate variable dice dice start meet girl pub study computer science think guy guy start count tree tree root girlfriend ask question convince dice throw dice number want probability density density let dice let label shake throw denote value cube value cube gesundheit situation produce segmentation fault problem mix know line row image student student work work use image grade use data format use image line power look happen probability happen thing write software use loop use constructor destructor second memory leak build know memory leak mean practice mean practice know technician hospital night look start system morning day know happen want tell want tell want tell build count grandma grandma know pay buck know money invest help look throw dice day write number throw thing list know sense let way end day know park beer come result frequency map know frequency grandma compute value entry convince girl pub guy complain root know complain start love love dice throw beer tonight number girl compute following throw number number estimate count frequency number end day time present guy save time value estimate mean saving saving girl look cube time entry dice game estimate power entry imagine fill know entry histogram entry dice dice assume datum need training datum estimate estimate model dependency estimate need sample datum estimate talk delete interpolation way fill histogram information space term dimension assume observation write probability probability probability probability observe image factorize way observation observe image know image use eliminate measure marginalization idea compute multiply prior image marginalize image probability observe image image eliminate image estimation generate maximize probability question compute filter image observe image instance gibb sampler method hear statistic attend lecture statistic course number level gibb sampler gibb sampler work follow compute estimate image configuration select point image modify point image grid modify way probability probability image increase probability measure change value image probability increase bit mean search space search compute gradient instance function search space question search way search use gibb sampler change intensity value look probability increase find configuration way change value posterior increase stop filter image start career professor exercise pain mean implement year result change compute posterior find mean allow thing publication use gibbs sampler point engineer engineering school forget solve mean write probability function function write approach solve equation result function solve way gibb sampler solve algorithm use analysis question markov field markov field abbreviate markov field use try use feature classification end day use kernel know talk markov field markov field satisfy follow property satisfy positivity constraint feature let probability observe configuration ask definition student tell positivity criterion answer positivity criterion end day model distribution achieve value reason sense come schema markov property markov property compute density density reduce density consider neighborhood markov property consider pixel neighborhood markov property yes positivity markov property fulfil markov field example image grid instance pixel value neighborhood ignore probability configuration instance introduce order dependency precede feature use instance hide markov modeling order dependency use dependency graph need bit graph theory assume set neighborhood system set point define neighborhood system neighborhood system define set neighbor condition fulfil point neighborhood point neighborhood point neighborhood prime neighbor consider let look example let denote grid grid lattice image processing image grid instance define neighborhood system point point consider point distance choose neighbor point coordinate neighbor consider point define neighborhood define use root element fall neighborhood define neighbor grid feature vector feature grid consider image use feature space need concept use definition circle sphere define neighborhood point space element sphere radius neighbor neighborhood neighborhood neighbor mean live door ignore neighbor definition neighbor need concept clique clique clique graph hear graph theory study computer science guy mean graph engineering mean look know circuit graph graph theory way describe talk clique book mathematic aesthetik esthetics engineer design circuit mathematician design circuit know path sense know graph theory write professor quarter book collaborate circuit come version stuff learn graph theory study engineering know think ignore activity challenge decision learn live clique hear graph theory know know min max maximum flow dijkstra algorithm stuff stuff learn know clique clique clique subgraph set subgraph clique subgraph graph graph vertex neighbor graph clique subset cardinality element mean graph example instance graph neighborhood include point clique course set clique clique vertex vertex neighbor pair pair pair pair pair set clique follow observation start minute leave minute moebius inversion stuff know student tell exam ask moebius inversion miss point lecture observation probability density function feature vector write form write density function form zero mean log power power log mean function know bureaucrat write course thing semester know comment course logarithm basis write way write function probability density function value form form gain gain lot define gibb field gibb field abbreviation believe abbreviation gibb field define probability density time power term partition function partitioning function prefactor assure end density integral domain yes scaling factor partition function define potential potential family object graph constraint potential set potential potential intersection select set intersection choose point set instance intersect look example energy function sum clique sum clique consider potential clique feature bit discuss example accept mind read density function function sum element graph neighborhood element graph result want point second result year day remember year landing moon year theorem markov field fulfill property negativity markov property dependency write associate density function form form define image neighborhood write density function form gibb distribution result proof proof need know moebius inversion formula combinatoric end day potential look math reason ask colleague professor strehl moebius inversion computer science lecture year student beginning course evaluation decide lecture evaluation care end mean discuss thing concept want research field technique hope enjoy lecture bit semester course pattern recognition theory overlap system theory filtering theory summer semester learn lot know pattern analysis machine learning technique field challenge field master thesis project instance mean look challenge lab place want invent thing people invent chose lab exaggerate thank attend beer reason master thesis project lab thank enjoy life
